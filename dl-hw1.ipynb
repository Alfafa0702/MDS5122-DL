{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assignment 1 - Code Example - Part A\n\nThis code baseline is inspired by and modified from [this great tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n\nThis code can achieve an accuracy of approximately 86.50% on CIFAR-10. Please set up the environment and run your experiments starting from this baseline. You are expected to achieve an accuracy higher than this baseline.","metadata":{}},{"cell_type":"code","source":"# import some necessary packages\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport torchvision.datasets as tv_datasets\nimport torchvision.transforms as tv_transforms","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T05:29:51.949204Z","iopub.execute_input":"2025-02-26T05:29:51.949497Z","iopub.status.idle":"2025-02-26T05:30:01.591581Z","shell.execute_reply.started":"2025-02-26T05:29:51.949467Z","shell.execute_reply":"2025-02-26T05:30:01.590893Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu121\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(\"CUDA Version:\", torch.version.cuda)\n    print(\"CUDA Device:\", torch.cuda.get_device_name(0))\nelse:\n    print(\"CUDA is not available.\")\n\nprint(f\"PyTorch Version: {torch.__version__}\")\nimport torchvision\nprint(f\"torchvision Version: {torchvision.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T05:41:47.446859Z","iopub.execute_input":"2025-02-26T05:41:47.447248Z","iopub.status.idle":"2025-02-26T05:41:47.564205Z","shell.execute_reply.started":"2025-02-26T05:41:47.447216Z","shell.execute_reply":"2025-02-26T05:41:47.563315Z"}},"outputs":[{"name":"stdout","text":"CUDA Version: 12.1\nCUDA Device: Tesla T4\nPyTorch Version: 2.5.1+cu121\ntorchvision Version: 0.20.1+cu121\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 1. Baseline Model\n### 1.1 Settings","metadata":{}},{"cell_type":"code","source":"# prepare datasets\n# preprocessing pipeline for input images\ntransformation = dict()\nfor data_type in (\"train\", \"test\"):\n    is_train = data_type==\"train\"\n    transformation[data_type] = tv_transforms.Compose(([\n        tv_transforms.RandomRotation(degrees=15),\n        tv_transforms.RandomHorizontalFlip(),\n        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n    ] if is_train else []) + \n    [\n        tv_transforms.ToTensor(),\n        tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n    ])\n    \nnum_workers = 2\ndataset, loader = {}, {}\nfor data_type in (\"train\", \"test\"):\n    is_train = data_type==\"train\"\n    dataset[data_type] = tv_datasets.CIFAR10(\n        root=\"./data\", train=is_train, download=True, transform=transformation[data_type],\n    )\n    loader[data_type] = torch.utils.data.DataLoader(\n        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n    )\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:07:20.727411Z","iopub.execute_input":"2025-02-25T13:07:20.727683Z","iopub.status.idle":"2025-02-25T13:07:27.601000Z","shell.execute_reply.started":"2025-02-25T13:07:20.727661Z","shell.execute_reply":"2025-02-25T13:07:27.600353Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:03<00:00, 48.5MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# some experimental setup\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nnum_epochs = 128\nbatch_size = 64\nprint_every = 200\n\noptim_name = \"Adam\"\noptim_kwargs = dict(\n    lr=3e-4,\n    weight_decay=1e-6,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:07:20.657398Z","iopub.execute_input":"2025-02-25T13:07:20.657814Z","iopub.status.idle":"2025-02-25T13:07:20.726361Z","shell.execute_reply.started":"2025-02-25T13:07:20.657790Z","shell.execute_reply":"2025-02-25T13:07:20.725571Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# our network architecture\nnet = nn.Sequential(\n    nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n    nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n    nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n    nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n    nn.Flatten(),\n    nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n    nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n    nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n    nn.Linear(128, 10),\n)\n\n# move to device\nnet.to(device)\n\n# print the number of parameters\nprint(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:07:27.602466Z","iopub.execute_input":"2025-02-25T13:07:27.602734Z","iopub.status.idle":"2025-02-25T13:07:27.884275Z","shell.execute_reply.started":"2025-02-25T13:07:27.602713Z","shell.execute_reply":"2025-02-25T13:07:27.883483Z"}},"outputs":[{"name":"stdout","text":"number of parameters: 7.28M\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### 1.2 Start Training","metadata":{}},{"cell_type":"code","source":"# the network optimizer\noptimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n\n# loss function\ncriterion = nn.CrossEntropyLoss()\n\n# training loop\nnet.train()\nfor epoch in range(num_epochs):\n\n    running_loss = 0.0\n    for i, (img, target) in enumerate(loader[\"train\"]):\n        img, target = img.to(device), target.to(device)\n\n        pred = net(img)\n        loss = criterion(pred, target)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % print_every == print_every - 1:\n            print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n            running_loss = 0.0\n\nprint(\"Finished Training\")","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:07:27.885135Z","iopub.execute_input":"2025-02-25T13:07:27.885362Z","iopub.status.idle":"2025-02-25T13:48:20.705567Z","shell.execute_reply.started":"2025-02-25T13:07:27.885342Z","shell.execute_reply":"2025-02-25T13:48:20.704629Z"}},"outputs":[{"name":"stdout","text":"[epoch=  1, iter=  200] loss: 2.196\n[epoch=  1, iter=  400] loss: 1.976\n[epoch=  1, iter=  600] loss: 1.884\n[epoch=  2, iter=  200] loss: 1.684\n[epoch=  2, iter=  400] loss: 1.612\n[epoch=  2, iter=  600] loss: 1.545\n[epoch=  3, iter=  200] loss: 1.445\n[epoch=  3, iter=  400] loss: 1.403\n[epoch=  3, iter=  600] loss: 1.363\n[epoch=  4, iter=  200] loss: 1.293\n[epoch=  4, iter=  400] loss: 1.256\n[epoch=  4, iter=  600] loss: 1.248\n[epoch=  5, iter=  200] loss: 1.178\n[epoch=  5, iter=  400] loss: 1.156\n[epoch=  5, iter=  600] loss: 1.149\n[epoch=  6, iter=  200] loss: 1.075\n[epoch=  6, iter=  400] loss: 1.081\n[epoch=  6, iter=  600] loss: 1.094\n[epoch=  7, iter=  200] loss: 1.006\n[epoch=  7, iter=  400] loss: 1.005\n[epoch=  7, iter=  600] loss: 1.000\n[epoch=  8, iter=  200] loss: 0.973\n[epoch=  8, iter=  400] loss: 0.963\n[epoch=  8, iter=  600] loss: 0.931\n[epoch=  9, iter=  200] loss: 0.907\n[epoch=  9, iter=  400] loss: 0.891\n[epoch=  9, iter=  600] loss: 0.905\n[epoch= 10, iter=  200] loss: 0.857\n[epoch= 10, iter=  400] loss: 0.863\n[epoch= 10, iter=  600] loss: 0.847\n[epoch= 11, iter=  200] loss: 0.832\n[epoch= 11, iter=  400] loss: 0.838\n[epoch= 11, iter=  600] loss: 0.810\n[epoch= 12, iter=  200] loss: 0.802\n[epoch= 12, iter=  400] loss: 0.784\n[epoch= 12, iter=  600] loss: 0.796\n[epoch= 13, iter=  200] loss: 0.747\n[epoch= 13, iter=  400] loss: 0.765\n[epoch= 13, iter=  600] loss: 0.752\n[epoch= 14, iter=  200] loss: 0.723\n[epoch= 14, iter=  400] loss: 0.723\n[epoch= 14, iter=  600] loss: 0.732\n[epoch= 15, iter=  200] loss: 0.714\n[epoch= 15, iter=  400] loss: 0.699\n[epoch= 15, iter=  600] loss: 0.710\n[epoch= 16, iter=  200] loss: 0.686\n[epoch= 16, iter=  400] loss: 0.686\n[epoch= 16, iter=  600] loss: 0.666\n[epoch= 17, iter=  200] loss: 0.666\n[epoch= 17, iter=  400] loss: 0.639\n[epoch= 17, iter=  600] loss: 0.656\n[epoch= 18, iter=  200] loss: 0.634\n[epoch= 18, iter=  400] loss: 0.637\n[epoch= 18, iter=  600] loss: 0.633\n[epoch= 19, iter=  200] loss: 0.618\n[epoch= 19, iter=  400] loss: 0.630\n[epoch= 19, iter=  600] loss: 0.621\n[epoch= 20, iter=  200] loss: 0.616\n[epoch= 20, iter=  400] loss: 0.597\n[epoch= 20, iter=  600] loss: 0.603\n[epoch= 21, iter=  200] loss: 0.587\n[epoch= 21, iter=  400] loss: 0.584\n[epoch= 21, iter=  600] loss: 0.606\n[epoch= 22, iter=  200] loss: 0.583\n[epoch= 22, iter=  400] loss: 0.575\n[epoch= 22, iter=  600] loss: 0.567\n[epoch= 23, iter=  200] loss: 0.562\n[epoch= 23, iter=  400] loss: 0.569\n[epoch= 23, iter=  600] loss: 0.560\n[epoch= 24, iter=  200] loss: 0.534\n[epoch= 24, iter=  400] loss: 0.554\n[epoch= 24, iter=  600] loss: 0.545\n[epoch= 25, iter=  200] loss: 0.519\n[epoch= 25, iter=  400] loss: 0.533\n[epoch= 25, iter=  600] loss: 0.549\n[epoch= 26, iter=  200] loss: 0.536\n[epoch= 26, iter=  400] loss: 0.517\n[epoch= 26, iter=  600] loss: 0.555\n[epoch= 27, iter=  200] loss: 0.496\n[epoch= 27, iter=  400] loss: 0.523\n[epoch= 27, iter=  600] loss: 0.531\n[epoch= 28, iter=  200] loss: 0.488\n[epoch= 28, iter=  400] loss: 0.514\n[epoch= 28, iter=  600] loss: 0.508\n[epoch= 29, iter=  200] loss: 0.501\n[epoch= 29, iter=  400] loss: 0.500\n[epoch= 29, iter=  600] loss: 0.494\n[epoch= 30, iter=  200] loss: 0.486\n[epoch= 30, iter=  400] loss: 0.479\n[epoch= 30, iter=  600] loss: 0.485\n[epoch= 31, iter=  200] loss: 0.484\n[epoch= 31, iter=  400] loss: 0.475\n[epoch= 31, iter=  600] loss: 0.493\n[epoch= 32, iter=  200] loss: 0.463\n[epoch= 32, iter=  400] loss: 0.462\n[epoch= 32, iter=  600] loss: 0.476\n[epoch= 33, iter=  200] loss: 0.445\n[epoch= 33, iter=  400] loss: 0.469\n[epoch= 33, iter=  600] loss: 0.459\n[epoch= 34, iter=  200] loss: 0.444\n[epoch= 34, iter=  400] loss: 0.443\n[epoch= 34, iter=  600] loss: 0.440\n[epoch= 35, iter=  200] loss: 0.445\n[epoch= 35, iter=  400] loss: 0.431\n[epoch= 35, iter=  600] loss: 0.446\n[epoch= 36, iter=  200] loss: 0.422\n[epoch= 36, iter=  400] loss: 0.435\n[epoch= 36, iter=  600] loss: 0.447\n[epoch= 37, iter=  200] loss: 0.426\n[epoch= 37, iter=  400] loss: 0.438\n[epoch= 37, iter=  600] loss: 0.419\n[epoch= 38, iter=  200] loss: 0.423\n[epoch= 38, iter=  400] loss: 0.430\n[epoch= 38, iter=  600] loss: 0.410\n[epoch= 39, iter=  200] loss: 0.404\n[epoch= 39, iter=  400] loss: 0.415\n[epoch= 39, iter=  600] loss: 0.415\n[epoch= 40, iter=  200] loss: 0.409\n[epoch= 40, iter=  400] loss: 0.410\n[epoch= 40, iter=  600] loss: 0.424\n[epoch= 41, iter=  200] loss: 0.405\n[epoch= 41, iter=  400] loss: 0.397\n[epoch= 41, iter=  600] loss: 0.411\n[epoch= 42, iter=  200] loss: 0.394\n[epoch= 42, iter=  400] loss: 0.404\n[epoch= 42, iter=  600] loss: 0.419\n[epoch= 43, iter=  200] loss: 0.402\n[epoch= 43, iter=  400] loss: 0.391\n[epoch= 43, iter=  600] loss: 0.393\n[epoch= 44, iter=  200] loss: 0.376\n[epoch= 44, iter=  400] loss: 0.391\n[epoch= 44, iter=  600] loss: 0.382\n[epoch= 45, iter=  200] loss: 0.388\n[epoch= 45, iter=  400] loss: 0.386\n[epoch= 45, iter=  600] loss: 0.401\n[epoch= 46, iter=  200] loss: 0.376\n[epoch= 46, iter=  400] loss: 0.379\n[epoch= 46, iter=  600] loss: 0.394\n[epoch= 47, iter=  200] loss: 0.361\n[epoch= 47, iter=  400] loss: 0.362\n[epoch= 47, iter=  600] loss: 0.389\n[epoch= 48, iter=  200] loss: 0.364\n[epoch= 48, iter=  400] loss: 0.359\n[epoch= 48, iter=  600] loss: 0.386\n[epoch= 49, iter=  200] loss: 0.337\n[epoch= 49, iter=  400] loss: 0.366\n[epoch= 49, iter=  600] loss: 0.378\n[epoch= 50, iter=  200] loss: 0.349\n[epoch= 50, iter=  400] loss: 0.354\n[epoch= 50, iter=  600] loss: 0.357\n[epoch= 51, iter=  200] loss: 0.344\n[epoch= 51, iter=  400] loss: 0.368\n[epoch= 51, iter=  600] loss: 0.347\n[epoch= 52, iter=  200] loss: 0.334\n[epoch= 52, iter=  400] loss: 0.355\n[epoch= 52, iter=  600] loss: 0.362\n[epoch= 53, iter=  200] loss: 0.336\n[epoch= 53, iter=  400] loss: 0.366\n[epoch= 53, iter=  600] loss: 0.353\n[epoch= 54, iter=  200] loss: 0.332\n[epoch= 54, iter=  400] loss: 0.342\n[epoch= 54, iter=  600] loss: 0.350\n[epoch= 55, iter=  200] loss: 0.335\n[epoch= 55, iter=  400] loss: 0.330\n[epoch= 55, iter=  600] loss: 0.357\n[epoch= 56, iter=  200] loss: 0.330\n[epoch= 56, iter=  400] loss: 0.340\n[epoch= 56, iter=  600] loss: 0.342\n[epoch= 57, iter=  200] loss: 0.318\n[epoch= 57, iter=  400] loss: 0.346\n[epoch= 57, iter=  600] loss: 0.325\n[epoch= 58, iter=  200] loss: 0.326\n[epoch= 58, iter=  400] loss: 0.331\n[epoch= 58, iter=  600] loss: 0.327\n[epoch= 59, iter=  200] loss: 0.308\n[epoch= 59, iter=  400] loss: 0.309\n[epoch= 59, iter=  600] loss: 0.326\n[epoch= 60, iter=  200] loss: 0.308\n[epoch= 60, iter=  400] loss: 0.322\n[epoch= 60, iter=  600] loss: 0.329\n[epoch= 61, iter=  200] loss: 0.302\n[epoch= 61, iter=  400] loss: 0.324\n[epoch= 61, iter=  600] loss: 0.326\n[epoch= 62, iter=  200] loss: 0.302\n[epoch= 62, iter=  400] loss: 0.318\n[epoch= 62, iter=  600] loss: 0.324\n[epoch= 63, iter=  200] loss: 0.317\n[epoch= 63, iter=  400] loss: 0.305\n[epoch= 63, iter=  600] loss: 0.324\n[epoch= 64, iter=  200] loss: 0.296\n[epoch= 64, iter=  400] loss: 0.322\n[epoch= 64, iter=  600] loss: 0.310\n[epoch= 65, iter=  200] loss: 0.293\n[epoch= 65, iter=  400] loss: 0.305\n[epoch= 65, iter=  600] loss: 0.306\n[epoch= 66, iter=  200] loss: 0.301\n[epoch= 66, iter=  400] loss: 0.319\n[epoch= 66, iter=  600] loss: 0.305\n[epoch= 67, iter=  200] loss: 0.301\n[epoch= 67, iter=  400] loss: 0.313\n[epoch= 67, iter=  600] loss: 0.301\n[epoch= 68, iter=  200] loss: 0.295\n[epoch= 68, iter=  400] loss: 0.298\n[epoch= 68, iter=  600] loss: 0.294\n[epoch= 69, iter=  200] loss: 0.280\n[epoch= 69, iter=  400] loss: 0.297\n[epoch= 69, iter=  600] loss: 0.313\n[epoch= 70, iter=  200] loss: 0.294\n[epoch= 70, iter=  400] loss: 0.302\n[epoch= 70, iter=  600] loss: 0.282\n[epoch= 71, iter=  200] loss: 0.299\n[epoch= 71, iter=  400] loss: 0.289\n[epoch= 71, iter=  600] loss: 0.293\n[epoch= 72, iter=  200] loss: 0.279\n[epoch= 72, iter=  400] loss: 0.282\n[epoch= 72, iter=  600] loss: 0.285\n[epoch= 73, iter=  200] loss: 0.267\n[epoch= 73, iter=  400] loss: 0.285\n[epoch= 73, iter=  600] loss: 0.287\n[epoch= 74, iter=  200] loss: 0.283\n[epoch= 74, iter=  400] loss: 0.288\n[epoch= 74, iter=  600] loss: 0.285\n[epoch= 75, iter=  200] loss: 0.274\n[epoch= 75, iter=  400] loss: 0.286\n[epoch= 75, iter=  600] loss: 0.289\n[epoch= 76, iter=  200] loss: 0.268\n[epoch= 76, iter=  400] loss: 0.290\n[epoch= 76, iter=  600] loss: 0.292\n[epoch= 77, iter=  200] loss: 0.264\n[epoch= 77, iter=  400] loss: 0.292\n[epoch= 77, iter=  600] loss: 0.296\n[epoch= 78, iter=  200] loss: 0.263\n[epoch= 78, iter=  400] loss: 0.273\n[epoch= 78, iter=  600] loss: 0.268\n[epoch= 79, iter=  200] loss: 0.270\n[epoch= 79, iter=  400] loss: 0.281\n[epoch= 79, iter=  600] loss: 0.296\n[epoch= 80, iter=  200] loss: 0.273\n[epoch= 80, iter=  400] loss: 0.285\n[epoch= 80, iter=  600] loss: 0.272\n[epoch= 81, iter=  200] loss: 0.271\n[epoch= 81, iter=  400] loss: 0.272\n[epoch= 81, iter=  600] loss: 0.269\n[epoch= 82, iter=  200] loss: 0.244\n[epoch= 82, iter=  400] loss: 0.278\n[epoch= 82, iter=  600] loss: 0.256\n[epoch= 83, iter=  200] loss: 0.261\n[epoch= 83, iter=  400] loss: 0.269\n[epoch= 83, iter=  600] loss: 0.265\n[epoch= 84, iter=  200] loss: 0.254\n[epoch= 84, iter=  400] loss: 0.252\n[epoch= 84, iter=  600] loss: 0.255\n[epoch= 85, iter=  200] loss: 0.252\n[epoch= 85, iter=  400] loss: 0.262\n[epoch= 85, iter=  600] loss: 0.250\n[epoch= 86, iter=  200] loss: 0.255\n[epoch= 86, iter=  400] loss: 0.259\n[epoch= 86, iter=  600] loss: 0.263\n[epoch= 87, iter=  200] loss: 0.246\n[epoch= 87, iter=  400] loss: 0.254\n[epoch= 87, iter=  600] loss: 0.260\n[epoch= 88, iter=  200] loss: 0.266\n[epoch= 88, iter=  400] loss: 0.266\n[epoch= 88, iter=  600] loss: 0.252\n[epoch= 89, iter=  200] loss: 0.245\n[epoch= 89, iter=  400] loss: 0.243\n[epoch= 89, iter=  600] loss: 0.263\n[epoch= 90, iter=  200] loss: 0.255\n[epoch= 90, iter=  400] loss: 0.250\n[epoch= 90, iter=  600] loss: 0.256\n[epoch= 91, iter=  200] loss: 0.263\n[epoch= 91, iter=  400] loss: 0.255\n[epoch= 91, iter=  600] loss: 0.251\n[epoch= 92, iter=  200] loss: 0.239\n[epoch= 92, iter=  400] loss: 0.232\n[epoch= 92, iter=  600] loss: 0.258\n[epoch= 93, iter=  200] loss: 0.241\n[epoch= 93, iter=  400] loss: 0.248\n[epoch= 93, iter=  600] loss: 0.246\n[epoch= 94, iter=  200] loss: 0.240\n[epoch= 94, iter=  400] loss: 0.249\n[epoch= 94, iter=  600] loss: 0.249\n[epoch= 95, iter=  200] loss: 0.227\n[epoch= 95, iter=  400] loss: 0.243\n[epoch= 95, iter=  600] loss: 0.226\n[epoch= 96, iter=  200] loss: 0.245\n[epoch= 96, iter=  400] loss: 0.240\n[epoch= 96, iter=  600] loss: 0.249\n[epoch= 97, iter=  200] loss: 0.235\n[epoch= 97, iter=  400] loss: 0.251\n[epoch= 97, iter=  600] loss: 0.252\n[epoch= 98, iter=  200] loss: 0.236\n[epoch= 98, iter=  400] loss: 0.227\n[epoch= 98, iter=  600] loss: 0.235\n[epoch= 99, iter=  200] loss: 0.225\n[epoch= 99, iter=  400] loss: 0.234\n[epoch= 99, iter=  600] loss: 0.241\n[epoch=100, iter=  200] loss: 0.236\n[epoch=100, iter=  400] loss: 0.252\n[epoch=100, iter=  600] loss: 0.221\n[epoch=101, iter=  200] loss: 0.219\n[epoch=101, iter=  400] loss: 0.229\n[epoch=101, iter=  600] loss: 0.226\n[epoch=102, iter=  200] loss: 0.244\n[epoch=102, iter=  400] loss: 0.244\n[epoch=102, iter=  600] loss: 0.220\n[epoch=103, iter=  200] loss: 0.225\n[epoch=103, iter=  400] loss: 0.223\n[epoch=103, iter=  600] loss: 0.226\n[epoch=104, iter=  200] loss: 0.221\n[epoch=104, iter=  400] loss: 0.216\n[epoch=104, iter=  600] loss: 0.239\n[epoch=105, iter=  200] loss: 0.220\n[epoch=105, iter=  400] loss: 0.239\n[epoch=105, iter=  600] loss: 0.231\n[epoch=106, iter=  200] loss: 0.216\n[epoch=106, iter=  400] loss: 0.215\n[epoch=106, iter=  600] loss: 0.242\n[epoch=107, iter=  200] loss: 0.213\n[epoch=107, iter=  400] loss: 0.231\n[epoch=107, iter=  600] loss: 0.226\n[epoch=108, iter=  200] loss: 0.220\n[epoch=108, iter=  400] loss: 0.221\n[epoch=108, iter=  600] loss: 0.237\n[epoch=109, iter=  200] loss: 0.209\n[epoch=109, iter=  400] loss: 0.212\n[epoch=109, iter=  600] loss: 0.227\n[epoch=110, iter=  200] loss: 0.222\n[epoch=110, iter=  400] loss: 0.235\n[epoch=110, iter=  600] loss: 0.210\n[epoch=111, iter=  200] loss: 0.220\n[epoch=111, iter=  400] loss: 0.227\n[epoch=111, iter=  600] loss: 0.222\n[epoch=112, iter=  200] loss: 0.216\n[epoch=112, iter=  400] loss: 0.223\n[epoch=112, iter=  600] loss: 0.218\n[epoch=113, iter=  200] loss: 0.210\n[epoch=113, iter=  400] loss: 0.215\n[epoch=113, iter=  600] loss: 0.230\n[epoch=114, iter=  200] loss: 0.203\n[epoch=114, iter=  400] loss: 0.215\n[epoch=114, iter=  600] loss: 0.218\n[epoch=115, iter=  200] loss: 0.214\n[epoch=115, iter=  400] loss: 0.209\n[epoch=115, iter=  600] loss: 0.209\n[epoch=116, iter=  200] loss: 0.207\n[epoch=116, iter=  400] loss: 0.207\n[epoch=116, iter=  600] loss: 0.224\n[epoch=117, iter=  200] loss: 0.197\n[epoch=117, iter=  400] loss: 0.200\n[epoch=117, iter=  600] loss: 0.235\n[epoch=118, iter=  200] loss: 0.213\n[epoch=118, iter=  400] loss: 0.222\n[epoch=118, iter=  600] loss: 0.218\n[epoch=119, iter=  200] loss: 0.206\n[epoch=119, iter=  400] loss: 0.200\n[epoch=119, iter=  600] loss: 0.216\n[epoch=120, iter=  200] loss: 0.209\n[epoch=120, iter=  400] loss: 0.218\n[epoch=120, iter=  600] loss: 0.223\n[epoch=121, iter=  200] loss: 0.197\n[epoch=121, iter=  400] loss: 0.214\n[epoch=121, iter=  600] loss: 0.207\n[epoch=122, iter=  200] loss: 0.229\n[epoch=122, iter=  400] loss: 0.219\n[epoch=122, iter=  600] loss: 0.203\n[epoch=123, iter=  200] loss: 0.205\n[epoch=123, iter=  400] loss: 0.198\n[epoch=123, iter=  600] loss: 0.201\n[epoch=124, iter=  200] loss: 0.208\n[epoch=124, iter=  400] loss: 0.201\n[epoch=124, iter=  600] loss: 0.209\n[epoch=125, iter=  200] loss: 0.194\n[epoch=125, iter=  400] loss: 0.213\n[epoch=125, iter=  600] loss: 0.206\n[epoch=126, iter=  200] loss: 0.203\n[epoch=126, iter=  400] loss: 0.197\n[epoch=126, iter=  600] loss: 0.193\n[epoch=127, iter=  200] loss: 0.204\n[epoch=127, iter=  400] loss: 0.202\n[epoch=127, iter=  600] loss: 0.202\n[epoch=128, iter=  200] loss: 0.207\n[epoch=128, iter=  400] loss: 0.192\n[epoch=128, iter=  600] loss: 0.209\nFinished Training\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### 1.3 Evaluating its accuracy","metadata":{}},{"cell_type":"code","source":"net.eval()\ncorrect, total = 0, 0\nwith torch.no_grad():\n    for img, target in loader[\"test\"]:\n        img, target = img.to(device), target.to(device)\n        \n        # make prediction\n        pred = net(img)\n        \n        # accumulate\n        total += len(target)\n        correct += (torch.argmax(pred, dim=1) == target).sum().item()\n\nprint(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:48:20.706640Z","iopub.execute_input":"2025-02-25T13:48:20.706884Z","iopub.status.idle":"2025-02-25T13:48:22.669607Z","shell.execute_reply.started":"2025-02-25T13:48:20.706861Z","shell.execute_reply":"2025-02-25T13:48:22.668641Z"}},"outputs":[{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 86.97%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 2. Variant 1\nChanging the NN architecture.","metadata":{}},{"cell_type":"code","source":"# prepare datasets\n# preprocessing pipeline for input images\ntransformation = dict()\nfor data_type in (\"train\", \"test\"):\n    is_train = data_type==\"train\"\n    transformation[data_type] = tv_transforms.Compose(([\n        tv_transforms.RandomRotation(degrees=15),\n        tv_transforms.RandomHorizontalFlip(),\n        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n    ] if is_train else []) + \n    [\n        tv_transforms.ToTensor(),\n        tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n    ])\n    \nnum_workers = 2\ndataset, loader = {}, {}\nfor data_type in (\"train\", \"test\"):\n    is_train = data_type==\"train\"\n    dataset[data_type] = tv_datasets.CIFAR10(\n        root=\"./data\", train=is_train, download=True, transform=transformation[data_type],\n    )\n    loader[data_type] = torch.utils.data.DataLoader(\n        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n    )\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T07:34:38.017970Z","iopub.execute_input":"2025-02-26T07:34:38.018330Z","iopub.status.idle":"2025-02-26T07:34:39.633723Z","shell.execute_reply.started":"2025-02-26T07:34:38.018302Z","shell.execute_reply":"2025-02-26T07:34:39.633099Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# some experimental setup\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nnum_epochs = 128\nbatch_size = 64\nprint_every = 200\n\noptim_name = \"Adam\"\noptim_kwargs = dict(\n    lr=3e-4,\n    weight_decay=1e-6,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T07:34:41.692730Z","iopub.execute_input":"2025-02-26T07:34:41.693005Z","iopub.status.idle":"2025-02-26T07:34:41.697202Z","shell.execute_reply.started":"2025-02-26T07:34:41.692985Z","shell.execute_reply":"2025-02-26T07:34:41.696472Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# our network architecture\n# 定义基本的残差块\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != self.expansion * out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * out_channels)\n            )\n\n    def forward(self, x):\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = self.relu(out)\n        return out\n\n# 定义ResNet34模型\nclass ResNet34(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ResNet34, self).__init__()\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(64, 3, stride=1)\n        self.layer2 = self._make_layer(128, 4, stride=2)\n        self.layer3 = self._make_layer(256, 6, stride=2)\n        self.layer4 = self._make_layer(512, 3, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n\n    def _make_layer(self, out_channels, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(BasicBlock(self.in_channels, out_channels, stride))\n            self.in_channels = out_channels * BasicBlock.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.maxpool(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avgpool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n\nnet = ResNet34(num_classes=10)\n\n# move to device\nnet.to(device)\n\n# print the number of parameters\nprint(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T07:34:44.688053Z","iopub.execute_input":"2025-02-26T07:34:44.688399Z","iopub.status.idle":"2025-02-26T07:34:44.897736Z","shell.execute_reply.started":"2025-02-26T07:34:44.688374Z","shell.execute_reply":"2025-02-26T07:34:44.897069Z"}},"outputs":[{"name":"stdout","text":"number of parameters: 21.29M\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# the network optimizer\noptimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n\n# loss function\ncriterion = nn.CrossEntropyLoss()\n\n# training loop\nnet.train()\nfor epoch in range(num_epochs):\n\n    running_loss = 0.0\n    for i, (img, target) in enumerate(loader[\"train\"]):\n        img, target = img.to(device), target.to(device)\n\n        pred = net(img)\n        loss = criterion(pred, target)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % print_every == print_every - 1:\n            print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n            running_loss = 0.0\n\nprint(\"Finished Training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T07:34:52.525545Z","iopub.execute_input":"2025-02-26T07:34:52.525859Z","execution_failed":"2025-02-26T08:57:49.026Z"}},"outputs":[{"name":"stdout","text":"[epoch=  1, iter=  200] loss: 1.871\n[epoch=  1, iter=  400] loss: 1.577\n[epoch=  1, iter=  600] loss: 1.471\n[epoch=  2, iter=  200] loss: 1.320\n[epoch=  2, iter=  400] loss: 1.275\n[epoch=  2, iter=  600] loss: 1.216\n[epoch=  3, iter=  200] loss: 1.145\n[epoch=  3, iter=  400] loss: 1.115\n[epoch=  3, iter=  600] loss: 1.105\n[epoch=  4, iter=  200] loss: 1.019\n[epoch=  4, iter=  400] loss: 1.037\n[epoch=  4, iter=  600] loss: 0.998\n[epoch=  5, iter=  200] loss: 0.950\n[epoch=  5, iter=  400] loss: 0.956\n[epoch=  5, iter=  600] loss: 0.948\n[epoch=  6, iter=  200] loss: 0.892\n[epoch=  6, iter=  400] loss: 0.888\n[epoch=  6, iter=  600] loss: 0.873\n[epoch=  7, iter=  200] loss: 0.837\n[epoch=  7, iter=  400] loss: 0.829\n[epoch=  7, iter=  600] loss: 0.829\n[epoch=  8, iter=  200] loss: 0.806\n[epoch=  8, iter=  400] loss: 0.801\n[epoch=  8, iter=  600] loss: 0.783\n[epoch=  9, iter=  200] loss: 0.760\n[epoch=  9, iter=  400] loss: 0.764\n[epoch=  9, iter=  600] loss: 0.762\n[epoch= 10, iter=  200] loss: 0.729\n[epoch= 10, iter=  400] loss: 0.737\n[epoch= 10, iter=  600] loss: 0.725\n[epoch= 11, iter=  200] loss: 0.716\n[epoch= 11, iter=  400] loss: 0.691\n[epoch= 11, iter=  600] loss: 0.706\n[epoch= 12, iter=  200] loss: 0.673\n[epoch= 12, iter=  400] loss: 0.683\n[epoch= 12, iter=  600] loss: 0.678\n[epoch= 13, iter=  200] loss: 0.667\n[epoch= 13, iter=  400] loss: 0.642\n[epoch= 13, iter=  600] loss: 0.666\n[epoch= 14, iter=  200] loss: 0.638\n[epoch= 14, iter=  400] loss: 0.639\n[epoch= 14, iter=  600] loss: 0.644\n[epoch= 15, iter=  200] loss: 0.624\n[epoch= 15, iter=  400] loss: 0.626\n[epoch= 15, iter=  600] loss: 0.599\n[epoch= 16, iter=  200] loss: 0.602\n[epoch= 16, iter=  400] loss: 0.613\n[epoch= 16, iter=  600] loss: 0.589\n[epoch= 17, iter=  200] loss: 0.580\n[epoch= 17, iter=  400] loss: 0.586\n[epoch= 17, iter=  600] loss: 0.579\n[epoch= 18, iter=  200] loss: 0.578\n[epoch= 18, iter=  400] loss: 0.574\n[epoch= 18, iter=  600] loss: 0.568\n[epoch= 19, iter=  200] loss: 0.559\n[epoch= 19, iter=  400] loss: 0.579\n[epoch= 19, iter=  600] loss: 0.554\n[epoch= 20, iter=  200] loss: 0.527\n[epoch= 20, iter=  400] loss: 0.548\n[epoch= 20, iter=  600] loss: 0.545\n[epoch= 21, iter=  200] loss: 0.529\n[epoch= 21, iter=  400] loss: 0.531\n[epoch= 21, iter=  600] loss: 0.526\n[epoch= 22, iter=  200] loss: 0.504\n[epoch= 22, iter=  400] loss: 0.528\n[epoch= 22, iter=  600] loss: 0.526\n[epoch= 23, iter=  200] loss: 0.506\n[epoch= 23, iter=  400] loss: 0.496\n[epoch= 23, iter=  600] loss: 0.498\n[epoch= 24, iter=  200] loss: 0.493\n[epoch= 24, iter=  400] loss: 0.491\n[epoch= 24, iter=  600] loss: 0.496\n[epoch= 25, iter=  200] loss: 0.484\n[epoch= 25, iter=  400] loss: 0.463\n[epoch= 25, iter=  600] loss: 0.504\n[epoch= 26, iter=  200] loss: 0.481\n[epoch= 26, iter=  400] loss: 0.476\n[epoch= 26, iter=  600] loss: 0.466\n[epoch= 27, iter=  200] loss: 0.451\n[epoch= 27, iter=  400] loss: 0.456\n[epoch= 27, iter=  600] loss: 0.468\n[epoch= 28, iter=  200] loss: 0.433\n[epoch= 28, iter=  400] loss: 0.455\n[epoch= 28, iter=  600] loss: 0.455\n[epoch= 29, iter=  200] loss: 0.432\n[epoch= 29, iter=  400] loss: 0.452\n[epoch= 29, iter=  600] loss: 0.449\n[epoch= 30, iter=  200] loss: 0.429\n[epoch= 30, iter=  400] loss: 0.450\n[epoch= 30, iter=  600] loss: 0.445\n[epoch= 31, iter=  200] loss: 0.398\n[epoch= 31, iter=  400] loss: 0.435\n[epoch= 31, iter=  600] loss: 0.422\n[epoch= 32, iter=  200] loss: 0.419\n[epoch= 32, iter=  400] loss: 0.433\n[epoch= 32, iter=  600] loss: 0.416\n[epoch= 33, iter=  200] loss: 0.406\n[epoch= 33, iter=  400] loss: 0.406\n[epoch= 33, iter=  600] loss: 0.417\n[epoch= 34, iter=  200] loss: 0.395\n[epoch= 34, iter=  400] loss: 0.411\n[epoch= 34, iter=  600] loss: 0.397\n[epoch= 35, iter=  200] loss: 0.392\n[epoch= 35, iter=  400] loss: 0.394\n[epoch= 35, iter=  600] loss: 0.412\n[epoch= 36, iter=  200] loss: 0.373\n[epoch= 36, iter=  400] loss: 0.378\n[epoch= 36, iter=  600] loss: 0.388\n[epoch= 37, iter=  200] loss: 0.371\n[epoch= 37, iter=  400] loss: 0.385\n[epoch= 37, iter=  600] loss: 0.371\n[epoch= 38, iter=  200] loss: 0.367\n[epoch= 38, iter=  400] loss: 0.386\n[epoch= 38, iter=  600] loss: 0.381\n[epoch= 39, iter=  200] loss: 0.363\n[epoch= 39, iter=  400] loss: 0.357\n[epoch= 39, iter=  600] loss: 0.363\n[epoch= 40, iter=  200] loss: 0.355\n[epoch= 40, iter=  400] loss: 0.367\n[epoch= 40, iter=  600] loss: 0.365\n[epoch= 41, iter=  200] loss: 0.342\n[epoch= 41, iter=  400] loss: 0.353\n[epoch= 41, iter=  600] loss: 0.372\n[epoch= 42, iter=  200] loss: 0.344\n[epoch= 42, iter=  400] loss: 0.358\n[epoch= 42, iter=  600] loss: 0.355\n[epoch= 43, iter=  200] loss: 0.344\n[epoch= 43, iter=  400] loss: 0.347\n[epoch= 43, iter=  600] loss: 0.354\n[epoch= 44, iter=  200] loss: 0.326\n[epoch= 44, iter=  400] loss: 0.330\n[epoch= 44, iter=  600] loss: 0.358\n[epoch= 45, iter=  200] loss: 0.335\n[epoch= 45, iter=  400] loss: 0.336\n[epoch= 45, iter=  600] loss: 0.336\n[epoch= 46, iter=  200] loss: 0.317\n[epoch= 46, iter=  400] loss: 0.339\n[epoch= 46, iter=  600] loss: 0.332\n[epoch= 47, iter=  200] loss: 0.318\n[epoch= 47, iter=  400] loss: 0.319\n[epoch= 47, iter=  600] loss: 0.322\n[epoch= 48, iter=  200] loss: 0.304\n[epoch= 48, iter=  400] loss: 0.316\n[epoch= 48, iter=  600] loss: 0.304\n[epoch= 49, iter=  200] loss: 0.285\n[epoch= 49, iter=  400] loss: 0.313\n[epoch= 49, iter=  600] loss: 0.320\n[epoch= 50, iter=  200] loss: 0.292\n[epoch= 50, iter=  400] loss: 0.301\n[epoch= 50, iter=  600] loss: 0.300\n[epoch= 51, iter=  200] loss: 0.287\n[epoch= 51, iter=  400] loss: 0.302\n[epoch= 51, iter=  600] loss: 0.291\n[epoch= 52, iter=  200] loss: 0.291\n[epoch= 52, iter=  400] loss: 0.304\n[epoch= 52, iter=  600] loss: 0.300\n[epoch= 53, iter=  200] loss: 0.281\n[epoch= 53, iter=  400] loss: 0.297\n[epoch= 53, iter=  600] loss: 0.292\n[epoch= 54, iter=  200] loss: 0.269\n[epoch= 54, iter=  400] loss: 0.294\n[epoch= 54, iter=  600] loss: 0.282\n[epoch= 55, iter=  200] loss: 0.280\n[epoch= 55, iter=  400] loss: 0.294\n[epoch= 55, iter=  600] loss: 0.287\n[epoch= 56, iter=  200] loss: 0.269\n[epoch= 56, iter=  400] loss: 0.267\n[epoch= 56, iter=  600] loss: 0.273\n[epoch= 57, iter=  200] loss: 0.265\n[epoch= 57, iter=  400] loss: 0.273\n[epoch= 57, iter=  600] loss: 0.283\n[epoch= 58, iter=  200] loss: 0.271\n[epoch= 58, iter=  400] loss: 0.264\n[epoch= 58, iter=  600] loss: 0.281\n[epoch= 59, iter=  200] loss: 0.258\n[epoch= 59, iter=  400] loss: 0.258\n[epoch= 59, iter=  600] loss: 0.269\n[epoch= 60, iter=  200] loss: 0.254\n[epoch= 60, iter=  400] loss: 0.266\n[epoch= 60, iter=  600] loss: 0.275\n[epoch= 61, iter=  200] loss: 0.257\n[epoch= 61, iter=  400] loss: 0.256\n[epoch= 61, iter=  600] loss: 0.256\n[epoch= 62, iter=  200] loss: 0.249\n[epoch= 62, iter=  400] loss: 0.261\n[epoch= 62, iter=  600] loss: 0.246\n[epoch= 63, iter=  200] loss: 0.232\n[epoch= 63, iter=  400] loss: 0.251\n[epoch= 63, iter=  600] loss: 0.260\n[epoch= 64, iter=  200] loss: 0.234\n[epoch= 64, iter=  400] loss: 0.252\n[epoch= 64, iter=  600] loss: 0.239\n[epoch= 65, iter=  200] loss: 0.232\n[epoch= 65, iter=  400] loss: 0.255\n[epoch= 65, iter=  600] loss: 0.252\n[epoch= 66, iter=  200] loss: 0.234\n[epoch= 66, iter=  400] loss: 0.235\n[epoch= 66, iter=  600] loss: 0.242\n[epoch= 67, iter=  200] loss: 0.230\n[epoch= 67, iter=  400] loss: 0.233\n[epoch= 67, iter=  600] loss: 0.238\n[epoch= 68, iter=  200] loss: 0.235\n[epoch= 68, iter=  400] loss: 0.238\n[epoch= 68, iter=  600] loss: 0.223\n[epoch= 69, iter=  200] loss: 0.216\n[epoch= 69, iter=  400] loss: 0.234\n[epoch= 69, iter=  600] loss: 0.221\n[epoch= 70, iter=  200] loss: 0.219\n[epoch= 70, iter=  400] loss: 0.219\n[epoch= 70, iter=  600] loss: 0.229\n[epoch= 71, iter=  200] loss: 0.212\n[epoch= 71, iter=  400] loss: 0.214\n[epoch= 71, iter=  600] loss: 0.246\n[epoch= 72, iter=  200] loss: 0.226\n[epoch= 72, iter=  400] loss: 0.217\n[epoch= 72, iter=  600] loss: 0.219\n[epoch= 73, iter=  200] loss: 0.199\n[epoch= 73, iter=  400] loss: 0.217\n[epoch= 73, iter=  600] loss: 0.227\n[epoch= 74, iter=  200] loss: 0.208\n[epoch= 74, iter=  400] loss: 0.218\n[epoch= 74, iter=  600] loss: 0.221\n[epoch= 75, iter=  200] loss: 0.191\n[epoch= 75, iter=  400] loss: 0.216\n[epoch= 75, iter=  600] loss: 0.221\n[epoch= 76, iter=  200] loss: 0.204\n[epoch= 76, iter=  400] loss: 0.208\n[epoch= 76, iter=  600] loss: 0.210\n[epoch= 77, iter=  200] loss: 0.189\n[epoch= 77, iter=  400] loss: 0.196\n[epoch= 77, iter=  600] loss: 0.207\n[epoch= 78, iter=  200] loss: 0.195\n[epoch= 78, iter=  400] loss: 0.209\n[epoch= 78, iter=  600] loss: 0.198\n[epoch= 79, iter=  200] loss: 0.205\n[epoch= 79, iter=  400] loss: 0.198\n[epoch= 79, iter=  600] loss: 0.201\n[epoch= 80, iter=  200] loss: 0.195\n[epoch= 80, iter=  400] loss: 0.198\n[epoch= 80, iter=  600] loss: 0.212\n[epoch= 81, iter=  200] loss: 0.192\n[epoch= 81, iter=  400] loss: 0.194\n[epoch= 81, iter=  600] loss: 0.195\n[epoch= 82, iter=  200] loss: 0.193\n[epoch= 82, iter=  400] loss: 0.196\n[epoch= 82, iter=  600] loss: 0.202\n[epoch= 83, iter=  200] loss: 0.186\n[epoch= 83, iter=  400] loss: 0.192\n[epoch= 83, iter=  600] loss: 0.204\n[epoch= 84, iter=  200] loss: 0.181\n[epoch= 84, iter=  400] loss: 0.195\n[epoch= 84, iter=  600] loss: 0.189\n[epoch= 85, iter=  200] loss: 0.189\n[epoch= 85, iter=  400] loss: 0.180\n[epoch= 85, iter=  600] loss: 0.195\n[epoch= 86, iter=  200] loss: 0.175\n[epoch= 86, iter=  400] loss: 0.182\n[epoch= 86, iter=  600] loss: 0.184\n[epoch= 87, iter=  200] loss: 0.180\n[epoch= 87, iter=  400] loss: 0.171\n[epoch= 87, iter=  600] loss: 0.178\n[epoch= 88, iter=  200] loss: 0.175\n[epoch= 88, iter=  400] loss: 0.183\n[epoch= 88, iter=  600] loss: 0.179\n[epoch= 89, iter=  200] loss: 0.173\n[epoch= 89, iter=  400] loss: 0.182\n[epoch= 89, iter=  600] loss: 0.177\n[epoch= 90, iter=  200] loss: 0.178\n[epoch= 90, iter=  400] loss: 0.189\n[epoch= 90, iter=  600] loss: 0.180\n[epoch= 91, iter=  200] loss: 0.165\n[epoch= 91, iter=  400] loss: 0.180\n[epoch= 91, iter=  600] loss: 0.166\n[epoch= 92, iter=  200] loss: 0.165\n[epoch= 92, iter=  400] loss: 0.175\n[epoch= 92, iter=  600] loss: 0.172\n[epoch= 93, iter=  200] loss: 0.163\n[epoch= 93, iter=  400] loss: 0.166\n[epoch= 93, iter=  600] loss: 0.169\n[epoch= 94, iter=  200] loss: 0.147\n[epoch= 94, iter=  400] loss: 0.168\n[epoch= 94, iter=  600] loss: 0.170\n[epoch= 95, iter=  200] loss: 0.156\n[epoch= 95, iter=  400] loss: 0.158\n[epoch= 95, iter=  600] loss: 0.169\n[epoch= 96, iter=  200] loss: 0.161\n[epoch= 96, iter=  400] loss: 0.159\n[epoch= 96, iter=  600] loss: 0.156\n[epoch= 97, iter=  200] loss: 0.159\n[epoch= 97, iter=  400] loss: 0.161\n[epoch= 97, iter=  600] loss: 0.162\n[epoch= 98, iter=  200] loss: 0.154\n[epoch= 98, iter=  400] loss: 0.159\n[epoch= 98, iter=  600] loss: 0.159\n[epoch= 99, iter=  200] loss: 0.148\n[epoch= 99, iter=  400] loss: 0.164\n[epoch= 99, iter=  600] loss: 0.164\n[epoch=100, iter=  200] loss: 0.156\n[epoch=100, iter=  400] loss: 0.173\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"net.eval()\ncorrect, total = 0, 0\nwith torch.no_grad():\n    for img, target in loader[\"test\"]:\n        img, target = img.to(device), target.to(device)\n        \n        # make prediction\n        pred = net(img)\n        \n        # accumulate\n        total += len(target)\n        correct += (torch.argmax(pred, dim=1) == target).sum().item()\n\nprint(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"execution_failed":"2025-02-26T08:57:49.027Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Variant 2\nChanging the optimizer and learning rate scheduler.","metadata":{}},{"cell_type":"code","source":"# prepare datasets\n# preprocessing pipeline for input images\ntransformation = dict()\nfor data_type in (\"train\", \"test\"):\n    is_train = data_type==\"train\"\n    transformation[data_type] = tv_transforms.Compose(([\n        tv_transforms.RandomRotation(degrees=15),\n        tv_transforms.RandomHorizontalFlip(),\n        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n    ] if is_train else []) + \n    [\n        tv_transforms.ToTensor(),\n        tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n    ])\n    \nnum_workers = 2\nbatch_size = 64\ndataset, loader = {}, {}\nfor data_type in (\"train\", \"test\"):\n    is_train = data_type==\"train\"\n    dataset[data_type] = tv_datasets.CIFAR10(\n        root=\"./data\", train=is_train, download=True, transform=transformation[data_type],\n    )\n    loader[data_type] = torch.utils.data.DataLoader(\n        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T05:41:56.206409Z","iopub.execute_input":"2025-02-26T05:41:56.206703Z","iopub.status.idle":"2025-02-26T05:42:05.294900Z","shell.execute_reply.started":"2025-02-26T05:41:56.206671Z","shell.execute_reply":"2025-02-26T05:42:05.293990Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:05<00:00, 29.7MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# some experimental setup\nfrom torch.optim import lr_scheduler\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nnum_epochs = 128\nprint_every = 200\n\nlr = 3e-4\noptim_name = \"AdamW\"\noptim_kwargs = dict(\n    lr=lr,\n    weight_decay=0.01, # 1e-6 试试0.1/0.01\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:34:14.157537Z","iopub.execute_input":"2025-02-26T06:34:14.157942Z","iopub.status.idle":"2025-02-26T06:34:14.162829Z","shell.execute_reply.started":"2025-02-26T06:34:14.157917Z","shell.execute_reply":"2025-02-26T06:34:14.161894Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### Results\nAdamW lr=3e-4,weight_decay=0.01 scheduler = lr_scheduler.StepLR(optimizer, step_size=15,gamma=0.1) last_loss = 0.464 acc = 83.82%\n\nAdamW lr=3e-4,weight_decay=0.01\nconstant + cooldown last_loss = 1.015 acc = 68.65%\n","metadata":{}},{"cell_type":"code","source":"# our network architecture\nnet = nn.Sequential(\n    nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n    nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n    nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n    nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n    nn.Flatten(),\n    nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n    nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n    nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n    nn.Linear(128, 10),\n)\n\n# move to device\nnet.to(device)\n\n# print the number of parameters\nprint(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:34:17.117156Z","iopub.execute_input":"2025-02-26T06:34:17.117432Z","iopub.status.idle":"2025-02-26T06:34:17.187985Z","shell.execute_reply.started":"2025-02-26T06:34:17.117412Z","shell.execute_reply":"2025-02-26T06:34:17.187363Z"}},"outputs":[{"name":"stdout","text":"number of parameters: 7.28M\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# the network optimizer\noptimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n\n# loss function\ncriterion = nn.CrossEntropyLoss()\n\n# the network lr_scheduler\n# scheduler = lr_scheduler.StepLR(optimizer, step_size=15,gamma=0.1)\n# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=num_epochs) #或者20？\n# constant + cooldown\ndef update_learn_rate(optimizer, alpha):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = alpha","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:34:19.197474Z","iopub.execute_input":"2025-02-26T06:34:19.197802Z","iopub.status.idle":"2025-02-26T06:34:19.204495Z","shell.execute_reply.started":"2025-02-26T06:34:19.197774Z","shell.execute_reply":"2025-02-26T06:34:19.203319Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# training loop\nnet.train()\nfor epoch in range(num_epochs):\n    \n    running_loss = 0.0\n    alpha = lr\n    for i, (img, target) in enumerate(loader[\"train\"]):\n        img, target = img.to(device), target.to(device)\n        # 调整学习率\n        if epoch <= 30 and (epoch + 1) % 5 == 0:\n            alpha *= 0.98\n            update_learn_rate(optimizer, alpha)  # 更新学习率\n        elif epoch > 30 and epoch <= 70 and (epoch + 1) % 5 == 0:\n            alpha *= 0.95\n            update_learn_rate(optimizer, alpha)\n        elif epoch > 70 and epoch <= 100 and (epoch + 1) % 5 == 0:\n            alpha *= 0.925\n            update_learn_rate(optimizer, alpha)\n        elif epoch > 100 and (epoch + 1) % 5 == 0:\n            alpha *= 0.5\n            update_learn_rate(optimizer, alpha)\n\n        pred = net(img)\n        loss = criterion(pred, target)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % print_every == print_every - 1:\n            print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n            running_loss = 0.0\n    scheduler.step()\nprint(\"Finished Training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:34:27.202478Z","iopub.execute_input":"2025-02-26T06:34:27.202754Z","iopub.status.idle":"2025-02-26T07:13:22.133352Z","shell.execute_reply.started":"2025-02-26T06:34:27.202732Z","shell.execute_reply":"2025-02-26T07:13:22.132336Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"[epoch=  1, iter=  200] loss: 2.236\n[epoch=  1, iter=  400] loss: 2.015\n[epoch=  1, iter=  600] loss: 1.858\n[epoch=  2, iter=  200] loss: 1.672\n[epoch=  2, iter=  400] loss: 1.597\n[epoch=  2, iter=  600] loss: 1.556\n[epoch=  3, iter=  200] loss: 1.446\n[epoch=  3, iter=  400] loss: 1.410\n[epoch=  3, iter=  600] loss: 1.377\n[epoch=  4, iter=  200] loss: 1.300\n[epoch=  4, iter=  400] loss: 1.266\n[epoch=  4, iter=  600] loss: 1.227\n[epoch=  5, iter=  200] loss: 1.118\n[epoch=  5, iter=  400] loss: 1.119\n[epoch=  5, iter=  600] loss: 1.106\n[epoch=  6, iter=  200] loss: 1.109\n[epoch=  6, iter=  400] loss: 1.095\n[epoch=  6, iter=  600] loss: 1.104\n[epoch=  7, iter=  200] loss: 1.102\n[epoch=  7, iter=  400] loss: 1.097\n[epoch=  7, iter=  600] loss: 1.099\n[epoch=  8, iter=  200] loss: 1.097\n[epoch=  8, iter=  400] loss: 1.101\n[epoch=  8, iter=  600] loss: 1.109\n[epoch=  9, iter=  200] loss: 1.096\n[epoch=  9, iter=  400] loss: 1.090\n[epoch=  9, iter=  600] loss: 1.105\n[epoch= 10, iter=  200] loss: 1.108\n[epoch= 10, iter=  400] loss: 1.080\n[epoch= 10, iter=  600] loss: 1.104\n[epoch= 11, iter=  200] loss: 1.092\n[epoch= 11, iter=  400] loss: 1.092\n[epoch= 11, iter=  600] loss: 1.082\n[epoch= 12, iter=  200] loss: 1.092\n[epoch= 12, iter=  400] loss: 1.086\n[epoch= 12, iter=  600] loss: 1.090\n[epoch= 13, iter=  200] loss: 1.065\n[epoch= 13, iter=  400] loss: 1.104\n[epoch= 13, iter=  600] loss: 1.087\n[epoch= 14, iter=  200] loss: 1.102\n[epoch= 14, iter=  400] loss: 1.080\n[epoch= 14, iter=  600] loss: 1.086\n[epoch= 15, iter=  200] loss: 1.088\n[epoch= 15, iter=  400] loss: 1.083\n[epoch= 15, iter=  600] loss: 1.093\n[epoch= 16, iter=  200] loss: 1.066\n[epoch= 16, iter=  400] loss: 1.078\n[epoch= 16, iter=  600] loss: 1.084\n[epoch= 17, iter=  200] loss: 1.071\n[epoch= 17, iter=  400] loss: 1.067\n[epoch= 17, iter=  600] loss: 1.073\n[epoch= 18, iter=  200] loss: 1.075\n[epoch= 18, iter=  400] loss: 1.072\n[epoch= 18, iter=  600] loss: 1.076\n[epoch= 19, iter=  200] loss: 1.087\n[epoch= 19, iter=  400] loss: 1.073\n[epoch= 19, iter=  600] loss: 1.078\n[epoch= 20, iter=  200] loss: 1.091\n[epoch= 20, iter=  400] loss: 1.073\n[epoch= 20, iter=  600] loss: 1.069\n[epoch= 21, iter=  200] loss: 1.071\n[epoch= 21, iter=  400] loss: 1.068\n[epoch= 21, iter=  600] loss: 1.071\n[epoch= 22, iter=  200] loss: 1.063\n[epoch= 22, iter=  400] loss: 1.060\n[epoch= 22, iter=  600] loss: 1.051\n[epoch= 23, iter=  200] loss: 1.076\n[epoch= 23, iter=  400] loss: 1.074\n[epoch= 23, iter=  600] loss: 1.062\n[epoch= 24, iter=  200] loss: 1.059\n[epoch= 24, iter=  400] loss: 1.056\n[epoch= 24, iter=  600] loss: 1.079\n[epoch= 25, iter=  200] loss: 1.086\n[epoch= 25, iter=  400] loss: 1.049\n[epoch= 25, iter=  600] loss: 1.054\n[epoch= 26, iter=  200] loss: 1.054\n[epoch= 26, iter=  400] loss: 1.059\n[epoch= 26, iter=  600] loss: 1.038\n[epoch= 27, iter=  200] loss: 1.069\n[epoch= 27, iter=  400] loss: 1.056\n[epoch= 27, iter=  600] loss: 1.059\n[epoch= 28, iter=  200] loss: 1.050\n[epoch= 28, iter=  400] loss: 1.049\n[epoch= 28, iter=  600] loss: 1.065\n[epoch= 29, iter=  200] loss: 1.053\n[epoch= 29, iter=  400] loss: 1.071\n[epoch= 29, iter=  600] loss: 1.042\n[epoch= 30, iter=  200] loss: 1.066\n[epoch= 30, iter=  400] loss: 1.037\n[epoch= 30, iter=  600] loss: 1.059\n[epoch= 31, iter=  200] loss: 1.046\n[epoch= 31, iter=  400] loss: 1.032\n[epoch= 31, iter=  600] loss: 1.058\n[epoch= 32, iter=  200] loss: 1.018\n[epoch= 32, iter=  400] loss: 1.058\n[epoch= 32, iter=  600] loss: 1.053\n[epoch= 33, iter=  200] loss: 1.040\n[epoch= 33, iter=  400] loss: 1.044\n[epoch= 33, iter=  600] loss: 1.046\n[epoch= 34, iter=  200] loss: 1.049\n[epoch= 34, iter=  400] loss: 1.041\n[epoch= 34, iter=  600] loss: 1.055\n[epoch= 35, iter=  200] loss: 1.058\n[epoch= 35, iter=  400] loss: 1.050\n[epoch= 35, iter=  600] loss: 1.050\n[epoch= 36, iter=  200] loss: 1.066\n[epoch= 36, iter=  400] loss: 1.027\n[epoch= 36, iter=  600] loss: 1.053\n[epoch= 37, iter=  200] loss: 1.044\n[epoch= 37, iter=  400] loss: 1.043\n[epoch= 37, iter=  600] loss: 1.067\n[epoch= 38, iter=  200] loss: 1.056\n[epoch= 38, iter=  400] loss: 1.043\n[epoch= 38, iter=  600] loss: 1.059\n[epoch= 39, iter=  200] loss: 1.043\n[epoch= 39, iter=  400] loss: 1.044\n[epoch= 39, iter=  600] loss: 1.053\n[epoch= 40, iter=  200] loss: 1.043\n[epoch= 40, iter=  400] loss: 1.044\n[epoch= 40, iter=  600] loss: 1.051\n[epoch= 41, iter=  200] loss: 1.050\n[epoch= 41, iter=  400] loss: 1.054\n[epoch= 41, iter=  600] loss: 1.040\n[epoch= 42, iter=  200] loss: 1.037\n[epoch= 42, iter=  400] loss: 1.048\n[epoch= 42, iter=  600] loss: 1.044\n[epoch= 43, iter=  200] loss: 1.043\n[epoch= 43, iter=  400] loss: 1.047\n[epoch= 43, iter=  600] loss: 1.028\n[epoch= 44, iter=  200] loss: 1.045\n[epoch= 44, iter=  400] loss: 1.040\n[epoch= 44, iter=  600] loss: 1.057\n[epoch= 45, iter=  200] loss: 1.050\n[epoch= 45, iter=  400] loss: 1.041\n[epoch= 45, iter=  600] loss: 1.039\n[epoch= 46, iter=  200] loss: 1.041\n[epoch= 46, iter=  400] loss: 1.042\n[epoch= 46, iter=  600] loss: 1.048\n[epoch= 47, iter=  200] loss: 1.043\n[epoch= 47, iter=  400] loss: 1.048\n[epoch= 47, iter=  600] loss: 1.040\n[epoch= 48, iter=  200] loss: 1.028\n[epoch= 48, iter=  400] loss: 1.044\n[epoch= 48, iter=  600] loss: 1.042\n[epoch= 49, iter=  200] loss: 1.045\n[epoch= 49, iter=  400] loss: 1.038\n[epoch= 49, iter=  600] loss: 1.039\n[epoch= 50, iter=  200] loss: 1.045\n[epoch= 50, iter=  400] loss: 1.045\n[epoch= 50, iter=  600] loss: 1.051\n[epoch= 51, iter=  200] loss: 1.033\n[epoch= 51, iter=  400] loss: 1.053\n[epoch= 51, iter=  600] loss: 1.041\n[epoch= 52, iter=  200] loss: 1.031\n[epoch= 52, iter=  400] loss: 1.032\n[epoch= 52, iter=  600] loss: 1.038\n[epoch= 53, iter=  200] loss: 1.024\n[epoch= 53, iter=  400] loss: 1.043\n[epoch= 53, iter=  600] loss: 1.041\n[epoch= 54, iter=  200] loss: 1.036\n[epoch= 54, iter=  400] loss: 1.043\n[epoch= 54, iter=  600] loss: 1.041\n[epoch= 55, iter=  200] loss: 1.036\n[epoch= 55, iter=  400] loss: 1.046\n[epoch= 55, iter=  600] loss: 1.045\n[epoch= 56, iter=  200] loss: 1.038\n[epoch= 56, iter=  400] loss: 1.044\n[epoch= 56, iter=  600] loss: 1.029\n[epoch= 57, iter=  200] loss: 1.045\n[epoch= 57, iter=  400] loss: 1.042\n[epoch= 57, iter=  600] loss: 1.046\n[epoch= 58, iter=  200] loss: 1.043\n[epoch= 58, iter=  400] loss: 1.036\n[epoch= 58, iter=  600] loss: 1.036\n[epoch= 59, iter=  200] loss: 1.043\n[epoch= 59, iter=  400] loss: 1.039\n[epoch= 59, iter=  600] loss: 1.033\n[epoch= 60, iter=  200] loss: 1.030\n[epoch= 60, iter=  400] loss: 1.048\n[epoch= 60, iter=  600] loss: 1.032\n[epoch= 61, iter=  200] loss: 1.031\n[epoch= 61, iter=  400] loss: 1.039\n[epoch= 61, iter=  600] loss: 1.029\n[epoch= 62, iter=  200] loss: 1.047\n[epoch= 62, iter=  400] loss: 1.027\n[epoch= 62, iter=  600] loss: 1.021\n[epoch= 63, iter=  200] loss: 1.044\n[epoch= 63, iter=  400] loss: 1.026\n[epoch= 63, iter=  600] loss: 1.025\n[epoch= 64, iter=  200] loss: 1.030\n[epoch= 64, iter=  400] loss: 1.027\n[epoch= 64, iter=  600] loss: 1.039\n[epoch= 65, iter=  200] loss: 1.034\n[epoch= 65, iter=  400] loss: 1.015\n[epoch= 65, iter=  600] loss: 1.035\n[epoch= 66, iter=  200] loss: 1.029\n[epoch= 66, iter=  400] loss: 1.022\n[epoch= 66, iter=  600] loss: 1.049\n[epoch= 67, iter=  200] loss: 1.012\n[epoch= 67, iter=  400] loss: 1.036\n[epoch= 67, iter=  600] loss: 1.042\n[epoch= 68, iter=  200] loss: 1.042\n[epoch= 68, iter=  400] loss: 1.024\n[epoch= 68, iter=  600] loss: 1.038\n[epoch= 69, iter=  200] loss: 1.028\n[epoch= 69, iter=  400] loss: 1.039\n[epoch= 69, iter=  600] loss: 1.026\n[epoch= 70, iter=  200] loss: 1.054\n[epoch= 70, iter=  400] loss: 1.025\n[epoch= 70, iter=  600] loss: 1.029\n[epoch= 71, iter=  200] loss: 1.042\n[epoch= 71, iter=  400] loss: 1.018\n[epoch= 71, iter=  600] loss: 1.028\n[epoch= 72, iter=  200] loss: 1.026\n[epoch= 72, iter=  400] loss: 1.022\n[epoch= 72, iter=  600] loss: 1.028\n[epoch= 73, iter=  200] loss: 1.038\n[epoch= 73, iter=  400] loss: 1.029\n[epoch= 73, iter=  600] loss: 1.011\n[epoch= 74, iter=  200] loss: 1.024\n[epoch= 74, iter=  400] loss: 1.034\n[epoch= 74, iter=  600] loss: 1.017\n[epoch= 75, iter=  200] loss: 1.032\n[epoch= 75, iter=  400] loss: 1.037\n[epoch= 75, iter=  600] loss: 1.031\n[epoch= 76, iter=  200] loss: 1.025\n[epoch= 76, iter=  400] loss: 1.017\n[epoch= 76, iter=  600] loss: 1.046\n[epoch= 77, iter=  200] loss: 1.041\n[epoch= 77, iter=  400] loss: 1.037\n[epoch= 77, iter=  600] loss: 1.029\n[epoch= 78, iter=  200] loss: 1.025\n[epoch= 78, iter=  400] loss: 1.027\n[epoch= 78, iter=  600] loss: 1.016\n[epoch= 79, iter=  200] loss: 1.028\n[epoch= 79, iter=  400] loss: 1.016\n[epoch= 79, iter=  600] loss: 1.039\n[epoch= 80, iter=  200] loss: 1.028\n[epoch= 80, iter=  400] loss: 1.038\n[epoch= 80, iter=  600] loss: 1.023\n[epoch= 81, iter=  200] loss: 1.027\n[epoch= 81, iter=  400] loss: 1.045\n[epoch= 81, iter=  600] loss: 1.029\n[epoch= 82, iter=  200] loss: 1.026\n[epoch= 82, iter=  400] loss: 1.028\n[epoch= 82, iter=  600] loss: 1.049\n[epoch= 83, iter=  200] loss: 1.040\n[epoch= 83, iter=  400] loss: 1.027\n[epoch= 83, iter=  600] loss: 1.027\n[epoch= 84, iter=  200] loss: 1.033\n[epoch= 84, iter=  400] loss: 1.031\n[epoch= 84, iter=  600] loss: 1.020\n[epoch= 85, iter=  200] loss: 1.018\n[epoch= 85, iter=  400] loss: 1.035\n[epoch= 85, iter=  600] loss: 1.025\n[epoch= 86, iter=  200] loss: 1.019\n[epoch= 86, iter=  400] loss: 1.023\n[epoch= 86, iter=  600] loss: 1.017\n[epoch= 87, iter=  200] loss: 1.039\n[epoch= 87, iter=  400] loss: 1.018\n[epoch= 87, iter=  600] loss: 1.001\n[epoch= 88, iter=  200] loss: 1.014\n[epoch= 88, iter=  400] loss: 1.035\n[epoch= 88, iter=  600] loss: 1.018\n[epoch= 89, iter=  200] loss: 1.026\n[epoch= 89, iter=  400] loss: 1.035\n[epoch= 89, iter=  600] loss: 1.043\n[epoch= 90, iter=  200] loss: 1.025\n[epoch= 90, iter=  400] loss: 1.022\n[epoch= 90, iter=  600] loss: 1.026\n[epoch= 91, iter=  200] loss: 1.026\n[epoch= 91, iter=  400] loss: 1.027\n[epoch= 91, iter=  600] loss: 1.012\n[epoch= 92, iter=  200] loss: 1.020\n[epoch= 92, iter=  400] loss: 1.033\n[epoch= 92, iter=  600] loss: 1.016\n[epoch= 93, iter=  200] loss: 1.023\n[epoch= 93, iter=  400] loss: 1.016\n[epoch= 93, iter=  600] loss: 1.018\n[epoch= 94, iter=  200] loss: 1.033\n[epoch= 94, iter=  400] loss: 1.005\n[epoch= 94, iter=  600] loss: 1.021\n[epoch= 95, iter=  200] loss: 1.027\n[epoch= 95, iter=  400] loss: 1.016\n[epoch= 95, iter=  600] loss: 1.024\n[epoch= 96, iter=  200] loss: 1.009\n[epoch= 96, iter=  400] loss: 1.036\n[epoch= 96, iter=  600] loss: 1.012\n[epoch= 97, iter=  200] loss: 1.016\n[epoch= 97, iter=  400] loss: 1.013\n[epoch= 97, iter=  600] loss: 1.030\n[epoch= 98, iter=  200] loss: 1.017\n[epoch= 98, iter=  400] loss: 1.029\n[epoch= 98, iter=  600] loss: 1.007\n[epoch= 99, iter=  200] loss: 1.034\n[epoch= 99, iter=  400] loss: 1.013\n[epoch= 99, iter=  600] loss: 1.029\n[epoch=100, iter=  200] loss: 1.020\n[epoch=100, iter=  400] loss: 1.011\n[epoch=100, iter=  600] loss: 1.014\n[epoch=101, iter=  200] loss: 1.009\n[epoch=101, iter=  400] loss: 1.015\n[epoch=101, iter=  600] loss: 1.028\n[epoch=102, iter=  200] loss: 1.017\n[epoch=102, iter=  400] loss: 1.018\n[epoch=102, iter=  600] loss: 1.024\n[epoch=103, iter=  200] loss: 0.997\n[epoch=103, iter=  400] loss: 1.026\n[epoch=103, iter=  600] loss: 1.014\n[epoch=104, iter=  200] loss: 1.016\n[epoch=104, iter=  400] loss: 1.026\n[epoch=104, iter=  600] loss: 1.010\n[epoch=105, iter=  200] loss: 1.011\n[epoch=105, iter=  400] loss: 1.004\n[epoch=105, iter=  600] loss: 1.015\n[epoch=106, iter=  200] loss: 1.021\n[epoch=106, iter=  400] loss: 0.999\n[epoch=106, iter=  600] loss: 1.021\n[epoch=107, iter=  200] loss: 1.017\n[epoch=107, iter=  400] loss: 1.024\n[epoch=107, iter=  600] loss: 1.028\n[epoch=108, iter=  200] loss: 1.022\n[epoch=108, iter=  400] loss: 1.007\n[epoch=108, iter=  600] loss: 1.010\n[epoch=109, iter=  200] loss: 1.002\n[epoch=109, iter=  400] loss: 1.019\n[epoch=109, iter=  600] loss: 1.015\n[epoch=110, iter=  200] loss: 1.019\n[epoch=110, iter=  400] loss: 1.015\n[epoch=110, iter=  600] loss: 1.028\n[epoch=111, iter=  200] loss: 1.017\n[epoch=111, iter=  400] loss: 1.020\n[epoch=111, iter=  600] loss: 1.021\n[epoch=112, iter=  200] loss: 1.026\n[epoch=112, iter=  400] loss: 1.006\n[epoch=112, iter=  600] loss: 1.029\n[epoch=113, iter=  200] loss: 1.017\n[epoch=113, iter=  400] loss: 1.035\n[epoch=113, iter=  600] loss: 1.017\n[epoch=114, iter=  200] loss: 1.016\n[epoch=114, iter=  400] loss: 1.017\n[epoch=114, iter=  600] loss: 1.010\n[epoch=115, iter=  200] loss: 1.029\n[epoch=115, iter=  400] loss: 1.004\n[epoch=115, iter=  600] loss: 1.030\n[epoch=116, iter=  200] loss: 1.013\n[epoch=116, iter=  400] loss: 1.016\n[epoch=116, iter=  600] loss: 1.028\n[epoch=117, iter=  200] loss: 1.009\n[epoch=117, iter=  400] loss: 1.008\n[epoch=117, iter=  600] loss: 1.038\n[epoch=118, iter=  200] loss: 1.026\n[epoch=118, iter=  400] loss: 1.026\n[epoch=118, iter=  600] loss: 0.999\n[epoch=119, iter=  200] loss: 1.012\n[epoch=119, iter=  400] loss: 1.015\n[epoch=119, iter=  600] loss: 1.038\n[epoch=120, iter=  200] loss: 1.001\n[epoch=120, iter=  400] loss: 1.014\n[epoch=120, iter=  600] loss: 1.020\n[epoch=121, iter=  200] loss: 1.026\n[epoch=121, iter=  400] loss: 1.021\n[epoch=121, iter=  600] loss: 1.006\n[epoch=122, iter=  200] loss: 0.994\n[epoch=122, iter=  400] loss: 1.030\n[epoch=122, iter=  600] loss: 1.025\n[epoch=123, iter=  200] loss: 1.015\n[epoch=123, iter=  400] loss: 1.016\n[epoch=123, iter=  600] loss: 1.013\n[epoch=124, iter=  200] loss: 1.018\n[epoch=124, iter=  400] loss: 1.005\n[epoch=124, iter=  600] loss: 1.002\n[epoch=125, iter=  200] loss: 1.013\n[epoch=125, iter=  400] loss: 1.011\n[epoch=125, iter=  600] loss: 1.020\n[epoch=126, iter=  200] loss: 1.007\n[epoch=126, iter=  400] loss: 1.003\n[epoch=126, iter=  600] loss: 1.012\n[epoch=127, iter=  200] loss: 1.011\n[epoch=127, iter=  400] loss: 1.014\n[epoch=127, iter=  600] loss: 1.007\n[epoch=128, iter=  200] loss: 1.014\n[epoch=128, iter=  400] loss: 0.998\n[epoch=128, iter=  600] loss: 1.015\nFinished Training\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"net.eval()\ncorrect, total = 0, 0\nwith torch.no_grad():\n    for img, target in loader[\"test\"]:\n        img, target = img.to(device), target.to(device)\n        \n        # make prediction\n        pred = net(img)\n        \n        # accumulate\n        total += len(target)\n        correct += (torch.argmax(pred, dim=1) == target).sum().item()\n\nprint(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T07:32:25.374546Z","iopub.execute_input":"2025-02-26T07:32:25.374929Z","iopub.status.idle":"2025-02-26T07:32:27.369602Z","shell.execute_reply.started":"2025-02-26T07:32:25.374898Z","shell.execute_reply":"2025-02-26T07:32:27.368674Z"}},"outputs":[{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 68.65%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## 4. Variant 3\nChanging the data augementation.  \nRef: https://zhuanlan.zhihu.com/p/49180361","metadata":{}},{"cell_type":"code","source":"# prepare datasets\n# preprocessing pipeline for input images\ntransformation = dict()\nfor data_type in (\"train\", \"test\"):\n    is_train = data_type==\"train\"\n    transformation[data_type] = tv_transforms.Compose(([\n        tv_transforms.RandomRotation(degrees=15),\n        tv_transforms.RandomHorizontalFlip(),\n        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n    ] if is_train else []) + \n    [\n        tv_transforms.ToTensor(),\n        tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n    ])\n    \nnum_workers = 2\nbatch_size = 64\ndataset, loader = {}, {}\nfor data_type in (\"train\", \"test\"):\n    is_train = data_type==\"train\"\n    dataset[data_type] = tv_datasets.CIFAR10(\n        root=\"./data\", train=is_train, download=True, transform=transformation[data_type],\n    )\n    loader[data_type] = torch.utils.data.DataLoader(\n        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:34:24.659184Z","iopub.execute_input":"2025-02-25T14:34:24.659524Z","iopub.status.idle":"2025-02-25T14:34:26.207599Z","shell.execute_reply.started":"2025-02-25T14:34:24.659499Z","shell.execute_reply":"2025-02-25T14:34:26.206930Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# some experimental setup\nfrom torch.optim import lr_scheduler\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nnum_epochs = 128\nprint_every = 200\n\noptim_name = \"AdamW\"\noptim_kwargs = dict(\n    lr=3e-4,\n    weight_decay=1e-6,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:35:27.507199Z","iopub.execute_input":"2025-02-25T14:35:27.507569Z","iopub.status.idle":"2025-02-25T14:35:27.511901Z","shell.execute_reply.started":"2025-02-25T14:35:27.507539Z","shell.execute_reply":"2025-02-25T14:35:27.510972Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# our network architecture\nnet = nn.Sequential(\n    nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n    nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n    nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n    nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n    nn.Flatten(),\n    nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n    nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n    nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n    nn.Linear(128, 10),\n)\n\n# move to device\nnet.to(device)\n\n# print the number of parameters\nprint(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:35:31.325680Z","iopub.execute_input":"2025-02-25T14:35:31.326002Z","iopub.status.idle":"2025-02-25T14:35:31.557580Z","shell.execute_reply.started":"2025-02-25T14:35:31.325976Z","shell.execute_reply":"2025-02-25T14:35:31.556809Z"}},"outputs":[{"name":"stdout","text":"number of parameters: 7.28M\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# the network optimizer\noptimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n\n# loss function\ncriterion = nn.CrossEntropyLoss()\n\n# the network lr_scheduler\nscheduler = lr_scheduler.StepLR(optimizer, step_size=15,gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:35:35.156297Z","iopub.execute_input":"2025-02-25T14:35:35.156629Z","iopub.status.idle":"2025-02-25T14:35:35.160898Z","shell.execute_reply.started":"2025-02-25T14:35:35.156603Z","shell.execute_reply":"2025-02-25T14:35:35.160032Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# training loop\nnet.train()\nfor epoch in range(num_epochs):\n    scheduler.step()\n    running_loss = 0.0\n    for i, (img, target) in enumerate(loader[\"train\"]):\n        img, target = img.to(device), target.to(device)\n\n        pred = net(img)\n        loss = criterion(pred, target)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % print_every == print_every - 1:\n            print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n            running_loss = 0.0\n    \nprint(\"Finished Training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:35:40.363863Z","iopub.execute_input":"2025-02-25T14:35:40.364174Z"}},"outputs":[{"name":"stdout","text":"[epoch=  1, iter=  200] loss: 2.192\n[epoch=  1, iter=  400] loss: 1.951\n[epoch=  1, iter=  600] loss: 1.837\n[epoch=  2, iter=  200] loss: 1.655\n[epoch=  2, iter=  400] loss: 1.617\n[epoch=  2, iter=  600] loss: 1.533\n[epoch=  3, iter=  200] loss: 1.448\n[epoch=  3, iter=  400] loss: 1.424\n[epoch=  3, iter=  600] loss: 1.388\n[epoch=  4, iter=  200] loss: 1.308\n[epoch=  4, iter=  400] loss: 1.305\n[epoch=  4, iter=  600] loss: 1.256\n[epoch=  5, iter=  200] loss: 1.214\n[epoch=  5, iter=  400] loss: 1.191\n[epoch=  5, iter=  600] loss: 1.142\n[epoch=  6, iter=  200] loss: 1.128\n[epoch=  6, iter=  400] loss: 1.099\n[epoch=  6, iter=  600] loss: 1.081\n[epoch=  7, iter=  200] loss: 1.055\n[epoch=  7, iter=  400] loss: 1.037\n[epoch=  7, iter=  600] loss: 1.026\n[epoch=  8, iter=  200] loss: 0.981\n[epoch=  8, iter=  400] loss: 0.974\n[epoch=  8, iter=  600] loss: 0.981\n[epoch=  9, iter=  200] loss: 0.916\n[epoch=  9, iter=  400] loss: 0.930\n[epoch=  9, iter=  600] loss: 0.918\n[epoch= 10, iter=  200] loss: 0.882\n[epoch= 10, iter=  400] loss: 0.896\n[epoch= 10, iter=  600] loss: 0.881\n[epoch= 11, iter=  200] loss: 0.839\n[epoch= 11, iter=  400] loss: 0.844\n[epoch= 11, iter=  600] loss: 0.839\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"net.eval()\ncorrect, total = 0, 0\nwith torch.no_grad():\n    for img, target in loader[\"test\"]:\n        img, target = img.to(device), target.to(device)\n        \n        # make prediction\n        pred = net(img)\n        \n        # accumulate\n        total += len(target)\n        correct += (torch.argmax(pred, dim=1) == target).sum().item()\n\nprint(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null}]}