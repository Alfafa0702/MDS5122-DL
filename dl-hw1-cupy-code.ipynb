{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "754fd085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:53:57.611946Z",
     "iopub.status.busy": "2025-03-15T16:53:57.611749Z",
     "iopub.status.idle": "2025-03-15T16:54:01.858017Z",
     "shell.execute_reply": "2025-03-15T16:54:01.857153Z"
    },
    "id": "Pboct6EURROE",
    "outputId": "7b43fc6d-fc16-45b9-ed12-c4c6bd104b0c",
    "papermill": {
     "duration": 4.255522,
     "end_time": "2025-03-15T16:54:01.859724",
     "exception": false,
     "start_time": "2025-03-15T16:53:57.604202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.10/dist-packages (12.2.0)\r\n",
      "Requirement already satisfied: numpy<1.27,>=1.20 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x) (1.26.4)\r\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x) (0.8.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.20->cupy-cuda12x) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.20->cupy-cuda12x) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.20->cupy-cuda12x) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.20->cupy-cuda12x) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.20->cupy-cuda12x) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.20->cupy-cuda12x) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27,>=1.20->cupy-cuda12x) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27,>=1.20->cupy-cuda12x) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<1.27,>=1.20->cupy-cuda12x) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<1.27,>=1.20->cupy-cuda12x) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<1.27,>=1.20->cupy-cuda12x) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install cupy-cuda12x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58cfe68a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:01.874216Z",
     "iopub.status.busy": "2025-03-15T16:54:01.873974Z",
     "iopub.status.idle": "2025-03-15T16:54:10.905394Z",
     "shell.execute_reply": "2025-03-15T16:54:10.904708Z"
    },
    "id": "XCuNRfoGRROI",
    "papermill": {
     "duration": 9.040197,
     "end_time": "2025-03-15T16:54:10.907076",
     "exception": false,
     "start_time": "2025-03-15T16:54:01.866879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as tv_datasets\n",
    "import torchvision.transforms as tv_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf666e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:10.921230Z",
     "iopub.status.busy": "2025-03-15T16:54:10.920908Z",
     "iopub.status.idle": "2025-03-15T16:54:11.310349Z",
     "shell.execute_reply": "2025-03-15T16:54:11.309564Z"
    },
    "papermill": {
     "duration": 0.397655,
     "end_time": "2025-03-15T16:54:11.311833",
     "exception": false,
     "start_time": "2025-03-15T16:54:10.914178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.0448 seconds\n",
      "GPU time: 0.0972 seconds\n"
     ]
    }
   ],
   "source": [
    "# 验证是否cupy成功使用了gpu\n",
    "import time\n",
    "# 创建大矩阵\n",
    "size = 1000\n",
    "# NumPy数组（CPU）\n",
    "a_cpu = np.random.random((size, size))\n",
    "b_cpu = np.random.random((size, size))\n",
    "# CuPy数组（GPU）\n",
    "a_gpu = cp.array(a_cpu)\n",
    "b_gpu = cp.array(b_cpu)\n",
    "\n",
    "# CPU计时\n",
    "start_cpu = time.time()\n",
    "c_cpu = np.dot(a_cpu, b_cpu)\n",
    "cpu_time = time.time() - start_cpu\n",
    "\n",
    "# GPU计时\n",
    "start_gpu = time.time()\n",
    "c_gpu = cp.dot(a_gpu, b_gpu)\n",
    "cp.cuda.Stream.null.synchronize()  # 确保GPU运算完成\n",
    "gpu_time = time.time() - start_gpu\n",
    "\n",
    "print(f\"CPU time: {cpu_time:.4f} seconds\")\n",
    "print(f\"GPU time: {gpu_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c632429",
   "metadata": {
    "id": "RYplsbLDRROJ",
    "papermill": {
     "duration": 0.005994,
     "end_time": "2025-03-15T16:54:11.324565",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.318571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfbcac83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.337628Z",
     "iopub.status.busy": "2025-03-15T16:54:11.337352Z",
     "iopub.status.idle": "2025-03-15T16:54:11.340908Z",
     "shell.execute_reply": "2025-03-15T16:54:11.340303Z"
    },
    "id": "1grFSJcHRROL",
    "papermill": {
     "duration": 0.011484,
     "end_time": "2025-03-15T16:54:11.342167",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.330683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Module:\n",
    "    @property\n",
    "    def params(self):\n",
    "        return []\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8186da34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.355432Z",
     "iopub.status.busy": "2025-03-15T16:54:11.355186Z",
     "iopub.status.idle": "2025-03-15T16:54:11.359461Z",
     "shell.execute_reply": "2025-03-15T16:54:11.358863Z"
    },
    "id": "9-fukvjKRROL",
    "papermill": {
     "duration": 0.012126,
     "end_time": "2025-03-15T16:54:11.360567",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.348441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sequential(Module, list):\n",
    "    def __init__(self, *module_lst):\n",
    "        super().__init__(module_lst)\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return sum([m.params for m in self], [])\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        for module in self:\n",
    "            y = module(y)\n",
    "        return y\n",
    "\n",
    "    def backward(self, dy):\n",
    "        dx = dy\n",
    "        for module in self[::-1]:\n",
    "            dx = module.backward(dx)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4460578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.373606Z",
     "iopub.status.busy": "2025-03-15T16:54:11.373404Z",
     "iopub.status.idle": "2025-03-15T16:54:11.376805Z",
     "shell.execute_reply": "2025-03-15T16:54:11.376172Z"
    },
    "id": "VNO4cK1hRROM",
    "papermill": {
     "duration": 0.011061,
     "end_time": "2025-03-15T16:54:11.377922",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.366861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 工具函数\n",
    "def to_cpu(x):\n",
    "    return cp.asnumpy(x) if isinstance(x, cp.ndarray) else x\n",
    "\n",
    "def to_gpu(x):\n",
    "    return cp.asarray(x) if isinstance(x, np.ndarray) else x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1260f3c",
   "metadata": {
    "id": "9hQwTDYDRRON",
    "papermill": {
     "duration": 0.005961,
     "end_time": "2025-03-15T16:54:11.390012",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.384051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c200e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.403188Z",
     "iopub.status.busy": "2025-03-15T16:54:11.402984Z",
     "iopub.status.idle": "2025-03-15T16:54:11.418310Z",
     "shell.execute_reply": "2025-03-15T16:54:11.417522Z"
    },
    "id": "nZ1LMSYNDKzM",
    "outputId": "3ebe7094-5edf-4c33-ceb4-eef2d03a230a",
    "papermill": {
     "duration": 0.023239,
     "end_time": "2025-03-15T16:54:11.419505",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.396266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv2d(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=False):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.stride = stride if isinstance(stride, tuple) else (stride, stride)\n",
    "        self.padding = padding if isinstance(padding, tuple) else (padding, padding)\n",
    "\n",
    "        scale = np.sqrt(2.0 / (in_channels * np.prod(self.kernel_size)))\n",
    "        self.weight = cp.random.normal(0, scale, (out_channels, in_channels, *self.kernel_size))\n",
    "        self.weight_grad = cp.zeros_like(self.weight)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = cp.zeros(out_channels)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return [dict(val=self.weight, grad=self.weight_grad)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        batch_size, _, h, w = x.shape\n",
    "        pad_h, pad_w = self.padding\n",
    "\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = cp.pad(x, ((0,0), (0,0), (pad_h,pad_h), (pad_w,pad_w)), 'constant')\n",
    "\n",
    "        out_h = (h + 2 * pad_h - self.kernel_size[0]) // self.stride[0] + 1\n",
    "        out_w = (w + 2 * pad_w - self.kernel_size[1]) // self.stride[1] + 1\n",
    "\n",
    "        col = self._im2col(x,out_h,out_w)\n",
    "        col_W = self.weight.reshape(self.out_channels, -1).T\n",
    "\n",
    "        out = cp.dot(col, col_W)\n",
    "        if self.bias is not None:\n",
    "            out += self.bias.data\n",
    "        out = out.reshape(batch_size, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.col = col\n",
    "        #print('A forward::Conv2d finished.')\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        batch_size, channels, h, w = self.x.shape\n",
    "        kh, kw = self.kernel_size\n",
    "        sh, sw = self.stride\n",
    "        ph,pw = self.padding\n",
    "\n",
    "        h_out = (h + 2*ph - kh) // sh + 1\n",
    "        w_out = (w + 2*pw - kw) // sw + 1\n",
    "\n",
    "        if self.bias is not None:\n",
    "            self.bias.grad = cp.sum(dout, axis=(0, 2, 3))\n",
    "\n",
    "        dout = dout.transpose(1,0,2,3).reshape(self.out_channels, -1)\n",
    "\n",
    "        self.weight_grad = cp.dot(dout, self.col).reshape(self.out_channels, self.in_channels, kh, kw)\n",
    "\n",
    "        dcol = cp.dot(dout.T, self.weight.reshape(self.out_channels, -1))\n",
    "        dcol = dcol.reshape(batch_size, h_out, w_out, self.in_channels, kh, kw)\n",
    "\n",
    "        dx = self._col2im(dcol,h_out,w_out)\n",
    "        # Remove padding\n",
    "        if ph > 0 or pw > 0:\n",
    "            dx = dx[:, :, ph:ph+h, pw:pw+w]\n",
    "        #print('A backward::Conv2d finished.')\n",
    "\n",
    "        return dx\n",
    "\n",
    "    def _im2col(self, x,out_h,out_w):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        kh, kw = self.kernel_size\n",
    "        sh, sw = self.stride\n",
    "        ph,pw = self.padding\n",
    "\n",
    "        x_padded = cp.pad(x, ((0, 0), (0, 0), (ph, ph), (pw, pw)), mode='constant')\n",
    "\n",
    "        col = cp.zeros((batch_size,channels,kh,kw,out_h,out_w))\n",
    "\n",
    "        for i in range(kh):\n",
    "            h_max = i + sh * out_h\n",
    "            for j in range(kw):\n",
    "                w_max = j + sw * out_w\n",
    "                col[:, :, i, j, :, :] = x_padded[:, :, i:h_max:sh, j:w_max:sw]\n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(batch_size * out_h * out_w, -1)\n",
    "\n",
    "        return col\n",
    "\n",
    "    def _col2im(self, col, out_h,out_w):\n",
    "        batch_size, channels, h,w = self.x.shape\n",
    "        kh, kw = self.kernel_size\n",
    "        sh, sw = self.stride\n",
    "        ph,pw = self.padding\n",
    "\n",
    "        img = cp.zeros((batch_size, self.in_channels, h + 2*ph, w + 2*pw))\n",
    "\n",
    "        for y in range(out_h):\n",
    "            y_start = y * sh\n",
    "            y_end = y_start + kh\n",
    "            for x in range(out_w):\n",
    "                x_start = x * sw\n",
    "                x_end = x_start + kw\n",
    "                grad_patch = col[:, y, x].reshape(batch_size, self.in_channels, kh, kw)\n",
    "                img[:, :, y_start:y_end, x_start:x_end] += grad_patch\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3627f6b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.432568Z",
     "iopub.status.busy": "2025-03-15T16:54:11.432325Z",
     "iopub.status.idle": "2025-03-15T16:54:11.436507Z",
     "shell.execute_reply": "2025-03-15T16:54:11.435703Z"
    },
    "id": "PBicpx7mRRON",
    "papermill": {
     "duration": 0.012187,
     "end_time": "2025-03-15T16:54:11.437836",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.425649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Conv2d(Module):\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "#         self.stride = stride if isinstance(stride, tuple) else (stride, stride)\n",
    "#         self.padding = padding if isinstance(padding, tuple) else (padding, padding)\n",
    "\n",
    "#         scale = np.sqrt(2.0 / (in_channels * np.prod(self.kernel_size)))\n",
    "#         self.weight = cp.random.normal(0, scale, (out_channels, in_channels, kernel_size))\n",
    "#         self.weight_grad = cp.zeros_like(self.weight)\n",
    "\n",
    "#     @property\n",
    "#     def params(self):\n",
    "#         return [dict(val=self.weight, grad=self.weight_grad)]\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         self.x = x\n",
    "#         batch_size, _, h, w = x.shape\n",
    "#         pad_h, pad_w = self.padding\n",
    "\n",
    "#         if pad_h > 0 or pad_w > 0:\n",
    "#             x = cp.pad(x, ((0,0), (0,0), (pad_h,pad_h), (pad_w,pad_w)), 'constant')\n",
    "\n",
    "#         out_h = (h + 2 * pad_h - self.kernel_size[0]) // self.stride[0] + 1\n",
    "#         out_w = (w + 2 * pad_w - self.kernel_size[1]) // self.stride[1] + 1\n",
    "\n",
    "#         col = self._im2col(x)\n",
    "#         col_W = self.weight.reshape(self.out_channels, -1).T\n",
    "#         print(f\"col:{col.shape}\")\n",
    "#         print(f\"col_W:{col_W.shape}\")\n",
    "#         out = cp.dot(col, col_W)\n",
    "#         out = out.reshape(batch_size, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "#         self.col = col\n",
    "#         return out\n",
    "\n",
    "#     def backward(self, dout):\n",
    "#         batch_size, _, h, w = dout.shape\n",
    "#         dout = dout.transpose(0,2,3,1).reshape(-1, self.out_channels)\n",
    "\n",
    "#         self.weight_grad = cp.dot(self.col.T, dout)\n",
    "#         self.weight_grad = self.weight_grad.transpose(1, 0)\n",
    "#         self.weight_grad = self.weight_grad.reshape(self.weight.shape)\n",
    "\n",
    "#         dcol = cp.dot(dout, self.weight.reshape(self.out_channels, -1))\n",
    "#         dx = self._col2im(dcol)\n",
    "\n",
    "#         return dx\n",
    "\n",
    "#     def _im2col(self, input_data):\n",
    "#         batch_size, channels, height, width = input_data.shape\n",
    "#         kh, kw = self.kernel_size\n",
    "#         sh, sw = self.stride\n",
    "#         ph, pw = self.padding\n",
    "\n",
    "#         # 计算输出尺寸\n",
    "#         out_h = (height + 2 * ph - kh) // sh + 1\n",
    "#         out_w = (width + 2 * pw - kw) // sw + 1\n",
    "\n",
    "#         # 创建输出矩阵\n",
    "#         col = cp.zeros((batch_size * out_h * out_w, channels * kh * kw))\n",
    "\n",
    "#         # 对每个滑动窗口位置进行操作\n",
    "#         for h_col in range(out_h):\n",
    "#             for w_col in range(out_w):\n",
    "#                 # 计算输入图像上的位置\n",
    "#                 h_im = h_col * sh - ph\n",
    "#                 w_im = w_col * sw - pw\n",
    "\n",
    "#                 # 对每个卷积核位置进行操作\n",
    "#                 for h_offset in range(kh):\n",
    "#                     h_im_pos = h_im + h_offset\n",
    "#                     for w_offset in range(kw):\n",
    "#                         w_im_pos = w_im + w_offset\n",
    "\n",
    "#                         # 计算当前输出位置在col中的索引\n",
    "#                         col_idx = (h_col * out_w + w_col)\n",
    "\n",
    "#                         # 计算kernel位置在channels_col中的偏移\n",
    "#                         channel_offset = (h_offset * kw + w_offset) * channels\n",
    "\n",
    "#                         # 如果在有效区域内，复制数据\n",
    "#                         if (0 <= h_im_pos < height) and (0 <= w_im_pos < width):\n",
    "#                             for b in range(batch_size):\n",
    "#                                 # 获取输入数据切片\n",
    "#                                 input_slice = input_data[b, :, h_im_pos, w_im_pos]\n",
    "#                                 # 写入col矩阵\n",
    "#                                 col[b * out_h * out_w + col_idx,\n",
    "#                                     channel_offset:channel_offset + channels] = input_slice\n",
    "\n",
    "#         return col\n",
    "\n",
    "#     def _col2im(self, col):\n",
    "#         batch_size, channels, height, width = self.x.shape\n",
    "#         kh, kw = self.kernel_size\n",
    "#         sh, sw = self.stride\n",
    "#         ph, pw = self.padding\n",
    "\n",
    "#         # 计算输出特征图大小\n",
    "#         out_h = (height + 2*ph - kh) // sh + 1\n",
    "#         out_w = (width + 2*pw - kw) // sw + 1\n",
    "\n",
    "#         # 创建输出图像，初始化为0\n",
    "#         img = cp.zeros((batch_size, channels, height, width))\n",
    "\n",
    "#         # 计算channels_col\n",
    "#         channels_col = channels * kh * kw\n",
    "\n",
    "#         # 对每个batch分别处理\n",
    "#         for b in range(batch_size):\n",
    "#             # 遍历展开后的通道\n",
    "#             for c_col in range(channels_col):\n",
    "#                 # 计算在原始图像中的位置\n",
    "#                 w_offset = c_col % kw\n",
    "#                 h_offset = (c_col // kw) % kh\n",
    "#                 c_im = c_col // (kh * kw)\n",
    "\n",
    "#                 # 遍历输出特征图的每个位置\n",
    "#                 for h_col in range(out_h):\n",
    "#                     # 计算在输入图像中的高度位置\n",
    "#                     h_im = h_col * sh - ph + h_offset\n",
    "\n",
    "#                     for w_col in range(out_w):\n",
    "#                         # 计算在输入图像中的宽度位置\n",
    "#                         w_im = w_col * sw - pw + w_offset\n",
    "\n",
    "#                         if (0 <= h_im < height) and (0 <= w_im < width):\n",
    "#                             # 累加贡献值\n",
    "#                             img[b, c_im, h_im, w_im] += \\\n",
    "#                                 col[b * out_h * out_w + h_col * out_w + w_col, c_col]\n",
    "\n",
    "#         return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8196a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.451689Z",
     "iopub.status.busy": "2025-03-15T16:54:11.451447Z",
     "iopub.status.idle": "2025-03-15T16:54:11.461231Z",
     "shell.execute_reply": "2025-03-15T16:54:11.460443Z"
    },
    "id": "bHOb3obqRROO",
    "papermill": {
     "duration": 0.018347,
     "end_time": "2025-03-15T16:54:11.462541",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.444194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchNorm2d(Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        self.training = True\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "\n",
    "        self.gamma = cp.ones(num_features)\n",
    "        self.beta = cp.zeros(num_features)\n",
    "        self.gamma_grad = cp.zeros_like(self.gamma)\n",
    "        self.beta_grad = cp.zeros_like(self.beta)\n",
    "\n",
    "        self.running_mean = cp.zeros(num_features)\n",
    "        self.running_var = cp.ones(num_features)\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return [\n",
    "            dict(val=self.gamma, grad=self.gamma_grad),\n",
    "            dict(val=self.beta, grad=self.beta_grad)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        N, C, H, W = x.shape\n",
    "\n",
    "        if self.training:\n",
    "            mu = x.mean(axis=(0,2,3), keepdims=True)\n",
    "            var = x.var(axis=(0,2,3), keepdims=True) + self.eps\n",
    "            std = cp.sqrt(var)\n",
    "\n",
    "            x_norm = (x - mu) / std\n",
    "            self.x_norm = x_norm\n",
    "\n",
    "            self.running_mean = self.momentum * mu.reshape(-1) + (1 - self.momentum) * self.running_mean\n",
    "            self.running_var = self.momentum * var.reshape(-1) + (1 - self.momentum) * self.running_var\n",
    "        else:\n",
    "            x_norm = (x - self.running_mean.reshape(1,C,1,1)) / cp.sqrt(self.running_var.reshape(1,C,1,1) + self.eps)\n",
    "            self.x_norm = x_norm\n",
    "\n",
    "        out = self.gamma.reshape(1,C,1,1) * x_norm + self.beta.reshape(1,C,1,1)\n",
    "        #print('A forward::BatchNorm2d finished.')\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, C, H, W = dout.shape\n",
    "\n",
    "        self.gamma_grad = (dout * self.x_norm).sum(axis=(0,2,3))\n",
    "        self.beta_grad = dout.sum(axis=(0,2,3))\n",
    "\n",
    "        dx_norm = dout * self.gamma.reshape(1,C,1,1)\n",
    "        dvar = (dx_norm * (self.x - self.x_norm.mean(axis=(0,2,3), keepdims=True)) * -0.5 *\n",
    "               (self.x_norm.var(axis=(0,2,3), keepdims=True) + self.eps) ** (-3/2)).sum(axis=(0,2,3), keepdims=True)\n",
    "        dmean = -dx_norm.sum(axis=(0,2,3), keepdims=True) / cp.sqrt(self.x_norm.var(axis=(0,2,3), keepdims=True) + self.eps)\n",
    "        dx = dx_norm / cp.sqrt(self.x_norm.var(axis=(0,2,3), keepdims=True) + self.eps) + dvar * 2 * (self.x - self.x_norm.mean(axis=(0,2,3), keepdims=True)) / (N*H*W) + dmean / (N*H*W)\n",
    "\n",
    "        #print('A backward::BatchNorm2d finished.')\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c327f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.475549Z",
     "iopub.status.busy": "2025-03-15T16:54:11.475339Z",
     "iopub.status.idle": "2025-03-15T16:54:11.482924Z",
     "shell.execute_reply": "2025-03-15T16:54:11.482369Z"
    },
    "id": "dk96c0KCRROP",
    "papermill": {
     "duration": 0.015452,
     "end_time": "2025-03-15T16:54:11.484075",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.468623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchNorm1d(Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        self.training = True\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "\n",
    "        self.gamma = cp.ones(num_features)\n",
    "        self.beta = cp.zeros(num_features)\n",
    "        self.gamma_grad = cp.zeros_like(self.gamma)\n",
    "        self.beta_grad = cp.zeros_like(self.beta)\n",
    "\n",
    "        self.running_mean = cp.zeros(num_features)\n",
    "        self.running_var = cp.ones(num_features)\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return [\n",
    "            dict(val=self.gamma, grad=self.gamma_grad),\n",
    "            dict(val=self.beta, grad=self.beta_grad)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        if self.training:\n",
    "            mu = x.mean(axis=0)\n",
    "            var = x.var(axis=0) + self.eps\n",
    "            std = cp.sqrt(var)\n",
    "\n",
    "            x_norm = (x - mu) / std\n",
    "            self.x_norm = x_norm\n",
    "\n",
    "            self.running_mean = self.momentum * mu + (1 - self.momentum) * self.running_mean\n",
    "            self.running_var = self.momentum * var + (1 - self.momentum) * self.running_var\n",
    "        else:\n",
    "            x_norm = (x - self.running_mean) / cp.sqrt(self.running_var + self.eps)\n",
    "            self.x_norm = x_norm\n",
    "\n",
    "        out = self.gamma * x_norm + self.beta\n",
    "        #print('A forward::BatchNorm1d finished.')\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N = dout.shape[0]\n",
    "\n",
    "        self.gamma_grad = (dout * self.x_norm).sum(axis=0)\n",
    "        self.beta_grad = dout.sum(axis=0)\n",
    "\n",
    "        dx_norm = dout * self.gamma\n",
    "        dvar = (dx_norm * (self.x - self.x_norm.mean(axis=0)) * -0.5 *\n",
    "               (self.x_norm.var(axis=0) + self.eps) ** (-3/2)).sum(axis=0)\n",
    "        dmean = -dx_norm.sum(axis=0) / cp.sqrt(self.x_norm.var(axis=0) + self.eps)\n",
    "        dx = dx_norm / cp.sqrt(self.x_norm.var(axis=0) + self.eps) + dvar * 2 * (self.x - self.x_norm.mean(axis=0)) / N + dmean / N\n",
    "        #print('A backward::BatchNorm1d finished.')\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de1023a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.497095Z",
     "iopub.status.busy": "2025-03-15T16:54:11.496898Z",
     "iopub.status.idle": "2025-03-15T16:54:11.500431Z",
     "shell.execute_reply": "2025-03-15T16:54:11.499727Z"
    },
    "id": "_3ToLB3lRROQ",
    "papermill": {
     "duration": 0.011403,
     "end_time": "2025-03-15T16:54:11.501683",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.490280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return cp.maximum(0, x)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * (self.x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb7ad2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.516520Z",
     "iopub.status.busy": "2025-03-15T16:54:11.516261Z",
     "iopub.status.idle": "2025-03-15T16:54:11.519994Z",
     "shell.execute_reply": "2025-03-15T16:54:11.519340Z"
    },
    "id": "Kx-BUKAY0kCH",
    "papermill": {
     "duration": 0.012374,
     "end_time": "2025-03-15T16:54:11.521349",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.508975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sigmoid(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = 1 / (1 + cp.exp(-x))\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.out * (1 - self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f15ef0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.535548Z",
     "iopub.status.busy": "2025-03-15T16:54:11.535342Z",
     "iopub.status.idle": "2025-03-15T16:54:11.539092Z",
     "shell.execute_reply": "2025-03-15T16:54:11.538507Z"
    },
    "id": "h5j1ASyW0j17",
    "papermill": {
     "duration": 0.012092,
     "end_time": "2025-03-15T16:54:11.540372",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.528280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeakyReLU(Module):\n",
    "    def __init__(self, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return cp.where(x > 0, x, x * self.negative_slope)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return cp.where(self.x > 0, dout, dout * self.negative_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af77aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.554187Z",
     "iopub.status.busy": "2025-03-15T16:54:11.553983Z",
     "iopub.status.idle": "2025-03-15T16:54:11.558025Z",
     "shell.execute_reply": "2025-03-15T16:54:11.557457Z"
    },
    "id": "X7RvkUdg0joo",
    "papermill": {
     "duration": 0.012244,
     "end_time": "2025-03-15T16:54:11.559247",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.547003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SELU(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.alpha = 1.6732632423543772848170429916717\n",
    "        self.scale = 1.0507009873554804934193349852946\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return self.scale * cp.where(x > 0, x, self.alpha * (cp.exp(x) - 1))\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return self.scale * cp.where(self.x > 0, dout, dout * self.alpha * cp.exp(self.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b935ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.573148Z",
     "iopub.status.busy": "2025-03-15T16:54:11.572943Z",
     "iopub.status.idle": "2025-03-15T16:54:11.580648Z",
     "shell.execute_reply": "2025-03-15T16:54:11.580005Z"
    },
    "id": "EReUR1dGRROQ",
    "papermill": {
     "duration": 0.015946,
     "end_time": "2025-03-15T16:54:11.581875",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.565929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MaxPool2d(Module):\n",
    "    def __init__(self, kernel_size, stride=None):\n",
    "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.stride = stride if stride is not None else self.kernel_size\n",
    "        self.stride = self.stride if isinstance(self.stride, tuple) else (self.stride, self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        N, C, H, W = x.shape\n",
    "        kh, kw = self.kernel_size\n",
    "        sh, sw = self.stride\n",
    "\n",
    "        out_h = (H - kh) // sh + 1\n",
    "        out_w = (W - kw) // sw + 1\n",
    "\n",
    "        col = cp.zeros((N * C * out_h * out_w, kh * kw))\n",
    "        for y in range(out_h):\n",
    "            y_start = y * sh\n",
    "            for x in range(out_w):\n",
    "                x_start = x * sw\n",
    "                receptive_field = self.x[:, :, y_start:y_start + kh, x_start:x_start + kw]\n",
    "                col[y * out_w + x::out_h * out_w] = receptive_field.reshape(N * C, -1)\n",
    "\n",
    "        self.max_indices = col.argmax(axis=1)\n",
    "        out = col[cp.arange(col.shape[0]), self.max_indices]\n",
    "        #print('A forward::MaxPool2d finished.')\n",
    "\n",
    "        return out.reshape(N, C, out_h, out_w)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, C, H, W = self.x.shape\n",
    "        kh, kw = self.kernel_size\n",
    "        sh, sw = self.stride\n",
    "\n",
    "        out_h = (H - kh) // sh + 1\n",
    "        out_w = (W - kw) // sw + 1\n",
    "\n",
    "        dx = cp.zeros_like(self.x)\n",
    "        dout_flat = dout.reshape(-1)\n",
    "\n",
    "        for i in range(dout_flat.shape[0]):\n",
    "            h_idx = (i // (C * out_w)) // out_h\n",
    "            w_idx = (i // C) % out_w\n",
    "            c_idx = i % C\n",
    "            h_start = h_idx * sh\n",
    "            w_start = w_idx * sw\n",
    "\n",
    "            max_idx = self.max_indices[i]\n",
    "            h_offset = max_idx // kw\n",
    "            w_offset = max_idx % kw\n",
    "\n",
    "            dx[h_idx, c_idx, h_start + h_offset, w_start + w_offset] += dout_flat[i]\n",
    "        #print('A backward::MaxPool2d finished.')\n",
    "\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "160f1df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.595836Z",
     "iopub.status.busy": "2025-03-15T16:54:11.595619Z",
     "iopub.status.idle": "2025-03-15T16:54:11.599655Z",
     "shell.execute_reply": "2025-03-15T16:54:11.599014Z"
    },
    "id": "x_ulne39RROR",
    "papermill": {
     "duration": 0.012512,
     "end_time": "2025-03-15T16:54:11.600895",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.588383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dropout(Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "        self.mask = None\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            self.mask = cp.random.rand(*x.shape) > self.p\n",
    "            return x * self.mask / (1 - self.p)\n",
    "        #print('A forward::Dropout finished.')\n",
    "        return x\n",
    "\n",
    "    def backward(self, dout):\n",
    "        #print('A backward::Dropout finished.')\n",
    "        return dout * self.mask / (1 - self.p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7a8156c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.614740Z",
     "iopub.status.busy": "2025-03-15T16:54:11.614531Z",
     "iopub.status.idle": "2025-03-15T16:54:11.619587Z",
     "shell.execute_reply": "2025-03-15T16:54:11.618960Z"
    },
    "id": "XVV2g2vlRROS",
    "papermill": {
     "duration": 0.013385,
     "end_time": "2025-03-15T16:54:11.620907",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.607522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        scale = np.sqrt(2.0 / in_features)\n",
    "        self.weight = cp.random.normal(0, scale, (out_features, in_features))\n",
    "        self.bias = cp.zeros(out_features)\n",
    "\n",
    "        self.weight_grad = cp.zeros_like(self.weight)\n",
    "        self.bias_grad = cp.zeros_like(self.bias)\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return [\n",
    "            dict(val=self.weight, grad=self.weight_grad),\n",
    "            dict(val=self.bias, grad=self.bias_grad)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        #print('A forward::Linear finished.')\n",
    "        return cp.dot(x, self.weight.T) + self.bias\n",
    "\n",
    "    def backward(self, dout):\n",
    "        self.weight_grad = cp.dot(dout.T, self.x)\n",
    "        self.bias_grad = dout.sum(axis=0)\n",
    "        #print('A backward::Linear finished.')\n",
    "        return cp.dot(dout, self.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77f9263e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.634530Z",
     "iopub.status.busy": "2025-03-15T16:54:11.634258Z",
     "iopub.status.idle": "2025-03-15T16:54:11.637913Z",
     "shell.execute_reply": "2025-03-15T16:54:11.637227Z"
    },
    "id": "QI1VeiikRROS",
    "papermill": {
     "duration": 0.011462,
     "end_time": "2025-03-15T16:54:11.639092",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.627630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Flatten(Module):\n",
    "    def forward(self, x):\n",
    "        self.input_shape = x.shape\n",
    "        #print('A forward::Flatten finished.')\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        #print('A backward::Flatten finished.')\n",
    "        return dout.reshape(self.input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce01da",
   "metadata": {
    "id": "PgiQoZDARROS",
    "papermill": {
     "duration": 0.005982,
     "end_time": "2025-03-15T16:54:11.651182",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.645200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss function, optimizer, and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75cd4ac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.664034Z",
     "iopub.status.busy": "2025-03-15T16:54:11.663838Z",
     "iopub.status.idle": "2025-03-15T16:54:11.668077Z",
     "shell.execute_reply": "2025-03-15T16:54:11.667508Z"
    },
    "id": "MD_LfMJORROS",
    "papermill": {
     "duration": 0.01197,
     "end_time": "2025-03-15T16:54:11.669334",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.657364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(Module):\n",
    "    def forward(self, x, target):\n",
    "        self.x = x\n",
    "        self.target = target\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x_shifted = x - cp.max(x, axis=1, keepdims=True)\n",
    "        exp_x = cp.exp(x_shifted)\n",
    "        self.softmax_x = exp_x / cp.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "        loss = -cp.log(self.softmax_x[cp.arange(batch_size), target] + 1e-7)\n",
    "        return loss.mean()\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.x.shape[0]\n",
    "        dx = self.softmax_x.copy()\n",
    "        dx[cp.arange(batch_size), self.target] -= 1\n",
    "        return dx * dout / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f4f07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.682607Z",
     "iopub.status.busy": "2025-03-15T16:54:11.682377Z",
     "iopub.status.idle": "2025-03-15T16:54:11.688525Z",
     "shell.execute_reply": "2025-03-15T16:54:11.687747Z"
    },
    "id": "yLk1XFjJ0rb0",
    "papermill": {
     "duration": 0.014268,
     "end_time": "2025-03-15T16:54:11.689834",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.675566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # 平衡因子\n",
    "        self.gamma = gamma  # 聚焦参数\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        self.x = x\n",
    "        self.target = target\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # 计算softmax\n",
    "        x_shifted = x - cp.max(x, axis=1, keepdims=True)\n",
    "        exp_x = cp.exp(x_shifted)\n",
    "        self.softmax_x = exp_x / cp.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "        # 获取目标类别的预测概率\n",
    "        pt = self.softmax_x[cp.arange(batch_size), target]\n",
    "\n",
    "        # 计算focal loss\n",
    "        self.pt = pt  # 保存用于反向传播\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "\n",
    "        # 添加alpha权重\n",
    "        alpha_weight = cp.ones_like(pt) * self.alpha\n",
    "        alpha_weight[target == 0] = 1 - self.alpha\n",
    "\n",
    "        loss = -alpha_weight * focal_weight * cp.log(pt + 1e-7)\n",
    "        return loss.mean()\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.x.shape[0]\n",
    "        dx = self.softmax_x.copy()\n",
    "\n",
    "        pt = self.pt\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "\n",
    "        # 计算梯度\n",
    "        for i in range(batch_size):\n",
    "            target_class = self.target[i]\n",
    "            alpha = self.alpha if target_class == 1 else (1 - self.alpha)\n",
    "            # focal loss对softmax输出的梯度\n",
    "            dx[i, target_class] -= 1\n",
    "            dx[i] *= alpha * focal_weight[i] * dout / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98454151",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.702767Z",
     "iopub.status.busy": "2025-03-15T16:54:11.702573Z",
     "iopub.status.idle": "2025-03-15T16:54:11.706529Z",
     "shell.execute_reply": "2025-03-15T16:54:11.705736Z"
    },
    "id": "ZP5i_0lzwi0f",
    "papermill": {
     "duration": 0.011673,
     "end_time": "2025-03-15T16:54:11.707663",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.695990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, params, lr=0.01):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            param[\"grad\"][:] = 0\n",
    "\n",
    "    def step(self):\n",
    "        for i, param in enumerate(self.params):\n",
    "            param[\"val\"] -= self.lr * param[\"grad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ceee58c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.720377Z",
     "iopub.status.busy": "2025-03-15T16:54:11.720126Z",
     "iopub.status.idle": "2025-03-15T16:54:11.725911Z",
     "shell.execute_reply": "2025-03-15T16:54:11.725325Z"
    },
    "id": "tubCCHyZRROS",
    "papermill": {
     "duration": 0.013461,
     "end_time": "2025-03-15T16:54:11.727097",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.713636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdamW:\n",
    "    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01):\n",
    "        self.params = params\n",
    "        self.lr = lr  # 在LRScheduler中的optimizer.lr当中被step()修改\n",
    "        self.beta1, self.beta2 = betas\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.m = [cp.zeros_like(p[\"val\"]) for p in params]\n",
    "        self.v = [cp.zeros_like(p[\"val\"]) for p in params]\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "\n",
    "        for i, param in enumerate(self.params):\n",
    "            g = param[\"grad\"]\n",
    "\n",
    "            if self.weight_decay > 0:\n",
    "                g = g + self.weight_decay * param[\"val\"]\n",
    "\n",
    "            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * g\n",
    "            mt = self.m[i] / (1 - self.beta1 ** self.t)\n",
    "\n",
    "            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (g * g)\n",
    "            vt = self.v[i] / (1 - self.beta2 ** self.t)\n",
    "\n",
    "            param[\"val\"] -= self.lr * mt / (cp.sqrt(vt) + self.eps)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            param[\"grad\"][:] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac8ec08e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.740442Z",
     "iopub.status.busy": "2025-03-15T16:54:11.740198Z",
     "iopub.status.idle": "2025-03-15T16:54:11.744905Z",
     "shell.execute_reply": "2025-03-15T16:54:11.744374Z"
    },
    "id": "6EaVJVGrRROT",
    "papermill": {
     "duration": 0.012666,
     "end_time": "2025-03-15T16:54:11.746033",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.733367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LRScheduler:\n",
    "    def __init__(self, optimizer, num_epochs, warmup_epochs=None, constant_epochs=None, initial_lr=3e-4, max_lr=3e-3):\n",
    "        self.optimizer = optimizer\n",
    "        self.num_epochs = num_epochs\n",
    "        self.warmup_epochs = warmup_epochs if warmup_epochs is not None else int(0.1 * num_epochs)\n",
    "        self.constant_epochs = constant_epochs if constant_epochs is not None else int(0.5 * num_epochs)\n",
    "        self.initial_lr = initial_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.current_lr = initial_lr\n",
    "\n",
    "    def step(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            # Warmup阶段：线性增加学习率\n",
    "            lr = self.initial_lr + (self.max_lr - self.initial_lr) * (epoch / self.warmup_epochs)\n",
    "        elif epoch < self.constant_epochs:\n",
    "            lr = self.max_lr\n",
    "        else:\n",
    "            # 后50%使用Cosine退火\n",
    "            progress = (epoch - self.warmup_epochs) / (self.num_epochs - self.warmup_epochs)\n",
    "            lr = self.max_lr * 0.5 * (1 + math.cos(progress * math.pi))\n",
    "\n",
    "        self.current_lr = lr\n",
    "        self.optimizer.lr = lr\n",
    "        return lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb43d5",
   "metadata": {
    "id": "BCvKLA1JRROT",
    "papermill": {
     "duration": 0.006137,
     "end_time": "2025-03-15T16:54:11.758385",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.752248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Simplified NN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e92c8f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.771066Z",
     "iopub.status.busy": "2025-03-15T16:54:11.770866Z",
     "iopub.status.idle": "2025-03-15T16:54:11.775068Z",
     "shell.execute_reply": "2025-03-15T16:54:11.774524Z"
    },
    "id": "q9TseVBzRROT",
    "papermill": {
     "duration": 0.011853,
     "end_time": "2025-03-15T16:54:11.776217",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.764364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    net = Sequential(\n",
    "        Conv2d(1, 64, 3, padding=1), ReLU(), BatchNorm2d(64),\n",
    "        Conv2d(64, 128, 3, padding=1), ReLU(), BatchNorm2d(128),\n",
    "        Conv2d(128, 128, 3, padding=1), ReLU(), BatchNorm2d(128),\n",
    "        Conv2d(128, 64, 3, padding=1), ReLU(), BatchNorm2d(64),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Linear(64 * 28 * 28, 128), ReLU(), Dropout(0.3), BatchNorm1d(128),\n",
    "        Linear(128, 64), ReLU(), Dropout(0.3), BatchNorm1d(64),\n",
    "        Linear(64, 10),\n",
    "    )\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f667e",
   "metadata": {
    "id": "1AWf1OHCRROT",
    "papermill": {
     "duration": 0.00593,
     "end_time": "2025-03-15T16:54:11.788251",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.782321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd307e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.801114Z",
     "iopub.status.busy": "2025-03-15T16:54:11.800919Z",
     "iopub.status.idle": "2025-03-15T16:54:11.806998Z",
     "shell.execute_reply": "2025-03-15T16:54:11.806224Z"
    },
    "id": "AglYNteGRROT",
    "papermill": {
     "duration": 0.013806,
     "end_time": "2025-03-15T16:54:11.808145",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.794339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, num_epochs=1, device=\"gpu\"):\n",
    "    # 初始化\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.params, lr=3e-4, weight_decay=1e-6)\n",
    "    scheduler = LRScheduler(optimizer, num_epochs=num_epochs)\n",
    "\n",
    "    # 记录训练历史\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_acc': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        model.training = True\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # 更新学习率\n",
    "        current_lr = scheduler.step(epoch)\n",
    "        history['learning_rates'].append(current_lr)\n",
    "\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            # 数据转换到GPU\n",
    "            if device == \"gpu\":\n",
    "                images = to_gpu(images.numpy())\n",
    "                targets = to_gpu(targets.numpy())\n",
    "                #print(f'Loader {i} start and has moved to GPU.')\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            #print(f'Loader {i} completed forward and loss.')\n",
    "\n",
    "            # 反向传播\n",
    "            model.backward(criterion.backward())\n",
    "            #print(f'Loader {i} completed backward.')\n",
    "\n",
    "            # 优化器步进\n",
    "            optimizer.step()\n",
    "            if i % 25 == 0 :\n",
    "                print(f'Loader {i} completed update.')\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 统计\n",
    "            running_loss += loss\n",
    "            if i % 100 == 99:\n",
    "                avg_loss = running_loss / 100\n",
    "                print(f'[Epoch {epoch + 1}, Batch {i + 1}] Loss: {avg_loss:.3f}, LR: {current_lr:.6f}')\n",
    "                history['train_loss'].append(avg_loss)\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # 每个epoch结束后评估\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            acc = evaluate(model, test_loader, device)\n",
    "            history['test_acc'].append(acc)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f403012b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.820947Z",
     "iopub.status.busy": "2025-03-15T16:54:11.820740Z",
     "iopub.status.idle": "2025-03-15T16:54:11.825069Z",
     "shell.execute_reply": "2025-03-15T16:54:11.824304Z"
    },
    "id": "TIYgLj34RROT",
    "papermill": {
     "duration": 0.012149,
     "end_time": "2025-03-15T16:54:11.826368",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.814219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device=\"gpu\"):\n",
    "    model.training = False\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with cp.cuda.Device(0):\n",
    "        for images, targets in test_loader:\n",
    "            if device == \"gpu\":\n",
    "                images = to_gpu(images.numpy())\n",
    "                targets = to_gpu(targets.numpy())\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = cp.argmax(outputs, axis=1)\n",
    "            total += targets.size\n",
    "            correct += (predictions == targets).sum()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb3c36",
   "metadata": {
    "id": "YXTAeo_fRROU",
    "papermill": {
     "duration": 0.006104,
     "end_time": "2025-03-15T16:54:11.838571",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.832467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b622cdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.851665Z",
     "iopub.status.busy": "2025-03-15T16:54:11.851429Z",
     "iopub.status.idle": "2025-03-15T16:54:11.920797Z",
     "shell.execute_reply": "2025-03-15T16:54:11.920121Z"
    },
    "id": "CxNN100ZSOrK",
    "outputId": "7beb84db-0826-471c-e51b-fc76b27d9bcd",
    "papermill": {
     "duration": 0.077278,
     "end_time": "2025-03-15T16:54:11.921966",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.844688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 12.1\n",
      "CUDA Device: Tesla T4\n",
      "PyTorch Version: 2.5.1+cu121\n",
      "torchvision Version: 0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Version:\", torch.version.cuda)\n",
    "    print(\"CUDA Device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "import torchvision\n",
    "print(f\"torchvision Version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f1562c3",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-15T16:54:11.935277Z",
     "iopub.status.busy": "2025-03-15T16:54:11.935061Z",
     "iopub.status.idle": "2025-03-15T22:11:50.389838Z",
     "shell.execute_reply": "2025-03-15T22:11:50.388828Z"
    },
    "id": "v1QcZ2kXRROU",
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 19058.463073,
     "end_time": "2025-03-15T22:11:50.391423",
     "exception": false,
     "start_time": "2025-03-15T16:54:11.928350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 36.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.16MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.28MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been collected.\n",
      "Model built\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 1, Batch 100] Loss: 2.946, LR: 0.000300\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 1, Batch 200] Loss: 2.795, LR: 0.000300\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 1, Batch 300] Loss: 2.664, LR: 0.000300\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 1, Batch 400] Loss: 2.581, LR: 0.000300\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 1, Batch 500] Loss: 2.451, LR: 0.000300\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 1, Batch 600] Loss: 2.312, LR: 0.000300\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 1, Batch 700] Loss: 2.303, LR: 0.000300\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 1, Batch 800] Loss: 2.303, LR: 0.000300\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 1, Batch 900] Loss: 2.303, LR: 0.000300\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.12%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 2, Batch 100] Loss: 2.303, LR: 0.001200\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 2, Batch 200] Loss: 2.303, LR: 0.001200\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 2, Batch 300] Loss: 2.303, LR: 0.001200\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 2, Batch 400] Loss: 2.303, LR: 0.001200\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 2, Batch 500] Loss: 2.303, LR: 0.001200\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 2, Batch 600] Loss: 2.303, LR: 0.001200\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 2, Batch 700] Loss: 2.303, LR: 0.001200\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 2, Batch 800] Loss: 2.303, LR: 0.001200\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 2, Batch 900] Loss: 2.303, LR: 0.001200\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 10.18%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 3, Batch 100] Loss: 2.303, LR: 0.002100\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 3, Batch 200] Loss: 2.303, LR: 0.002100\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 3, Batch 300] Loss: 2.303, LR: 0.002100\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 3, Batch 400] Loss: 2.303, LR: 0.002100\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 3, Batch 500] Loss: 2.303, LR: 0.002100\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 3, Batch 600] Loss: 2.303, LR: 0.002100\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 3, Batch 700] Loss: 2.303, LR: 0.002100\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 3, Batch 800] Loss: 2.303, LR: 0.002100\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 3, Batch 900] Loss: 2.303, LR: 0.002100\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 10.61%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 4, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 4, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 4, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 4, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 4, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 4, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 4, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 4, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 4, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 5, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 5, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 5, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 5, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 5, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 5, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 5, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 5, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 5, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 6, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 6, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 6, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 6, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 6, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 6, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 6, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 6, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 6, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 7, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 7, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 7, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 7, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 7, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 7, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 7, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 7, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 7, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 8, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 8, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 8, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 8, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 8, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 8, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 8, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 8, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 8, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 9, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 9, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 9, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 9, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 9, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 9, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 9, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 9, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 9, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 10, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 10, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 10, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 10, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 10, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 10, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 10, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 10, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 10, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 11, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 11, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 11, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 11, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 11, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 11, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 11, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 11, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 11, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 12, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 12, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 12, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 12, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 12, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 12, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 12, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 12, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 12, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 13, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 13, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 13, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 13, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 13, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 13, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 13, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 13, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 13, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 14, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 14, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 14, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 14, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 14, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 14, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 14, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 14, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 14, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 15, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 15, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 15, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 15, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 15, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 15, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 15, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 15, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 15, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 16, Batch 100] Loss: 2.303, LR: 0.003000\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 16, Batch 200] Loss: 2.303, LR: 0.003000\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 16, Batch 300] Loss: 2.303, LR: 0.003000\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 16, Batch 400] Loss: 2.303, LR: 0.003000\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 16, Batch 500] Loss: 2.303, LR: 0.003000\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 16, Batch 600] Loss: 2.303, LR: 0.003000\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 16, Batch 700] Loss: 2.303, LR: 0.003000\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 16, Batch 800] Loss: 2.303, LR: 0.003000\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 16, Batch 900] Loss: 2.303, LR: 0.003000\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 17, Batch 100] Loss: 2.303, LR: 0.001743\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 17, Batch 200] Loss: 2.303, LR: 0.001743\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 17, Batch 300] Loss: 2.303, LR: 0.001743\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 17, Batch 400] Loss: 2.303, LR: 0.001743\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 17, Batch 500] Loss: 2.303, LR: 0.001743\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 17, Batch 600] Loss: 2.303, LR: 0.001743\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 17, Batch 700] Loss: 2.303, LR: 0.001743\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 17, Batch 800] Loss: 2.303, LR: 0.001743\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 17, Batch 900] Loss: 2.303, LR: 0.001743\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 18, Batch 100] Loss: 2.303, LR: 0.001581\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 18, Batch 200] Loss: 2.303, LR: 0.001581\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 18, Batch 300] Loss: 2.303, LR: 0.001581\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 18, Batch 400] Loss: 2.303, LR: 0.001581\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 18, Batch 500] Loss: 2.303, LR: 0.001581\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 18, Batch 600] Loss: 2.303, LR: 0.001581\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 18, Batch 700] Loss: 2.303, LR: 0.001581\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 18, Batch 800] Loss: 2.303, LR: 0.001581\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 18, Batch 900] Loss: 2.303, LR: 0.001581\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 19, Batch 100] Loss: 2.303, LR: 0.001419\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 19, Batch 200] Loss: 2.303, LR: 0.001419\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 19, Batch 300] Loss: 2.303, LR: 0.001419\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 19, Batch 400] Loss: 2.303, LR: 0.001419\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 19, Batch 500] Loss: 2.303, LR: 0.001419\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 19, Batch 600] Loss: 2.303, LR: 0.001419\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 19, Batch 700] Loss: 2.303, LR: 0.001419\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 19, Batch 800] Loss: 2.303, LR: 0.001419\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 19, Batch 900] Loss: 2.303, LR: 0.001419\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 20, Batch 100] Loss: 2.303, LR: 0.001257\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 20, Batch 200] Loss: 2.303, LR: 0.001257\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 20, Batch 300] Loss: 2.303, LR: 0.001257\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 20, Batch 400] Loss: 2.303, LR: 0.001257\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 20, Batch 500] Loss: 2.303, LR: 0.001257\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 20, Batch 600] Loss: 2.303, LR: 0.001257\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 20, Batch 700] Loss: 2.303, LR: 0.001257\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 20, Batch 800] Loss: 2.303, LR: 0.001257\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 20, Batch 900] Loss: 2.303, LR: 0.001257\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 21, Batch 100] Loss: 2.303, LR: 0.001099\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 21, Batch 200] Loss: 2.303, LR: 0.001099\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 21, Batch 300] Loss: 2.303, LR: 0.001099\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 21, Batch 400] Loss: 2.303, LR: 0.001099\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 21, Batch 500] Loss: 2.303, LR: 0.001099\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 21, Batch 600] Loss: 2.303, LR: 0.001099\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 21, Batch 700] Loss: 2.303, LR: 0.001099\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 21, Batch 800] Loss: 2.303, LR: 0.001099\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 21, Batch 900] Loss: 2.303, LR: 0.001099\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 22, Batch 100] Loss: 2.303, LR: 0.000945\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 22, Batch 200] Loss: 2.303, LR: 0.000945\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 22, Batch 300] Loss: 2.303, LR: 0.000945\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 22, Batch 400] Loss: 2.303, LR: 0.000945\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 22, Batch 500] Loss: 2.303, LR: 0.000945\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 22, Batch 600] Loss: 2.303, LR: 0.000945\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 22, Batch 700] Loss: 2.303, LR: 0.000945\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 22, Batch 800] Loss: 2.303, LR: 0.000945\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 22, Batch 900] Loss: 2.303, LR: 0.000945\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 23, Batch 100] Loss: 2.303, LR: 0.000797\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 23, Batch 200] Loss: 2.303, LR: 0.000797\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 23, Batch 300] Loss: 2.303, LR: 0.000797\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 23, Batch 400] Loss: 2.303, LR: 0.000797\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 23, Batch 500] Loss: 2.303, LR: 0.000797\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 23, Batch 600] Loss: 2.303, LR: 0.000797\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 23, Batch 700] Loss: 2.303, LR: 0.000797\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 23, Batch 800] Loss: 2.303, LR: 0.000797\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 23, Batch 900] Loss: 2.303, LR: 0.000797\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 24, Batch 100] Loss: 2.303, LR: 0.000658\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 24, Batch 200] Loss: 2.303, LR: 0.000658\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 24, Batch 300] Loss: 2.303, LR: 0.000658\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 24, Batch 400] Loss: 2.303, LR: 0.000658\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 24, Batch 500] Loss: 2.303, LR: 0.000658\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 24, Batch 600] Loss: 2.303, LR: 0.000658\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 24, Batch 700] Loss: 2.303, LR: 0.000658\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 24, Batch 800] Loss: 2.303, LR: 0.000658\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 24, Batch 900] Loss: 2.303, LR: 0.000658\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 25, Batch 100] Loss: 2.303, LR: 0.000529\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 25, Batch 200] Loss: 2.303, LR: 0.000529\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 25, Batch 300] Loss: 2.303, LR: 0.000529\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 25, Batch 400] Loss: 2.303, LR: 0.000529\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 25, Batch 500] Loss: 2.303, LR: 0.000529\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 25, Batch 600] Loss: 2.303, LR: 0.000529\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 25, Batch 700] Loss: 2.303, LR: 0.000529\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 25, Batch 800] Loss: 2.303, LR: 0.000529\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 25, Batch 900] Loss: 2.303, LR: 0.000529\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 26, Batch 100] Loss: 2.303, LR: 0.000411\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 26, Batch 200] Loss: 2.303, LR: 0.000411\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 26, Batch 300] Loss: 2.303, LR: 0.000411\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 26, Batch 400] Loss: 2.303, LR: 0.000411\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 26, Batch 500] Loss: 2.303, LR: 0.000411\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 26, Batch 600] Loss: 2.303, LR: 0.000411\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 26, Batch 700] Loss: 2.303, LR: 0.000411\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 26, Batch 800] Loss: 2.303, LR: 0.000411\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 26, Batch 900] Loss: 2.303, LR: 0.000411\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 27, Batch 100] Loss: 2.303, LR: 0.000306\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 27, Batch 200] Loss: 2.303, LR: 0.000306\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 27, Batch 300] Loss: 2.303, LR: 0.000306\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 27, Batch 400] Loss: 2.303, LR: 0.000306\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 27, Batch 500] Loss: 2.303, LR: 0.000306\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 27, Batch 600] Loss: 2.303, LR: 0.000306\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 27, Batch 700] Loss: 2.303, LR: 0.000306\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 27, Batch 800] Loss: 2.303, LR: 0.000306\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 27, Batch 900] Loss: 2.303, LR: 0.000306\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 28, Batch 100] Loss: 2.303, LR: 0.000215\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 28, Batch 200] Loss: 2.303, LR: 0.000215\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 28, Batch 300] Loss: 2.303, LR: 0.000215\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 28, Batch 400] Loss: 2.303, LR: 0.000215\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 28, Batch 500] Loss: 2.303, LR: 0.000215\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 28, Batch 600] Loss: 2.303, LR: 0.000215\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 28, Batch 700] Loss: 2.303, LR: 0.000215\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 28, Batch 800] Loss: 2.303, LR: 0.000215\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 28, Batch 900] Loss: 2.303, LR: 0.000215\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 29, Batch 100] Loss: 2.303, LR: 0.000139\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 29, Batch 200] Loss: 2.303, LR: 0.000139\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 29, Batch 300] Loss: 2.303, LR: 0.000139\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 29, Batch 400] Loss: 2.303, LR: 0.000139\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 29, Batch 500] Loss: 2.303, LR: 0.000139\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 29, Batch 600] Loss: 2.303, LR: 0.000139\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 29, Batch 700] Loss: 2.303, LR: 0.000139\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 29, Batch 800] Loss: 2.303, LR: 0.000139\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 29, Batch 900] Loss: 2.303, LR: 0.000139\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 30, Batch 100] Loss: 2.303, LR: 0.000079\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 30, Batch 200] Loss: 2.303, LR: 0.000079\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 30, Batch 300] Loss: 2.303, LR: 0.000079\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 30, Batch 400] Loss: 2.303, LR: 0.000079\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 30, Batch 500] Loss: 2.303, LR: 0.000079\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 30, Batch 600] Loss: 2.303, LR: 0.000079\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 30, Batch 700] Loss: 2.303, LR: 0.000079\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 30, Batch 800] Loss: 2.303, LR: 0.000079\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 30, Batch 900] Loss: 2.303, LR: 0.000079\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 31, Batch 100] Loss: 2.303, LR: 0.000035\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 31, Batch 200] Loss: 2.303, LR: 0.000035\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 31, Batch 300] Loss: 2.303, LR: 0.000035\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 31, Batch 400] Loss: 2.303, LR: 0.000035\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 31, Batch 500] Loss: 2.303, LR: 0.000035\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 31, Batch 600] Loss: 2.303, LR: 0.000035\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 31, Batch 700] Loss: 2.303, LR: 0.000035\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 31, Batch 800] Loss: 2.303, LR: 0.000035\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 31, Batch 900] Loss: 2.303, LR: 0.000035\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n",
      "Loader 0 completed update.\n",
      "Loader 25 completed update.\n",
      "Loader 50 completed update.\n",
      "Loader 75 completed update.\n",
      "[Epoch 32, Batch 100] Loss: 2.303, LR: 0.000009\n",
      "Loader 100 completed update.\n",
      "Loader 125 completed update.\n",
      "Loader 150 completed update.\n",
      "Loader 175 completed update.\n",
      "[Epoch 32, Batch 200] Loss: 2.303, LR: 0.000009\n",
      "Loader 200 completed update.\n",
      "Loader 225 completed update.\n",
      "Loader 250 completed update.\n",
      "Loader 275 completed update.\n",
      "[Epoch 32, Batch 300] Loss: 2.303, LR: 0.000009\n",
      "Loader 300 completed update.\n",
      "Loader 325 completed update.\n",
      "Loader 350 completed update.\n",
      "Loader 375 completed update.\n",
      "[Epoch 32, Batch 400] Loss: 2.303, LR: 0.000009\n",
      "Loader 400 completed update.\n",
      "Loader 425 completed update.\n",
      "Loader 450 completed update.\n",
      "Loader 475 completed update.\n",
      "[Epoch 32, Batch 500] Loss: 2.303, LR: 0.000009\n",
      "Loader 500 completed update.\n",
      "Loader 525 completed update.\n",
      "Loader 550 completed update.\n",
      "Loader 575 completed update.\n",
      "[Epoch 32, Batch 600] Loss: 2.303, LR: 0.000009\n",
      "Loader 600 completed update.\n",
      "Loader 625 completed update.\n",
      "Loader 650 completed update.\n",
      "Loader 675 completed update.\n",
      "[Epoch 32, Batch 700] Loss: 2.303, LR: 0.000009\n",
      "Loader 700 completed update.\n",
      "Loader 725 completed update.\n",
      "Loader 750 completed update.\n",
      "Loader 775 completed update.\n",
      "[Epoch 32, Batch 800] Loss: 2.303, LR: 0.000009\n",
      "Loader 800 completed update.\n",
      "Loader 825 completed update.\n",
      "Loader 850 completed update.\n",
      "Loader 875 completed update.\n",
      "[Epoch 32, Batch 900] Loss: 2.303, LR: 0.000009\n",
      "Loader 900 completed update.\n",
      "Loader 925 completed update.\n",
      "Accuracy on test set: 9.80%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs=32\n",
    "if __name__ == '__main__':\n",
    "    # 数据增强\n",
    "    transform_train = tv_transforms.Compose([\n",
    "        tv_transforms.RandomCrop(28, padding=4, padding_mode='reflect'),\n",
    "        tv_transforms.RandomHorizontalFlip(),\n",
    "        tv_transforms.RandomRotation(degrees=15),\n",
    "        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        tv_transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        tv_transforms.ToTensor(),\n",
    "        tv_transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        tv_transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),\n",
    "    ])\n",
    "\n",
    "    transform_test = tv_transforms.Compose([\n",
    "        tv_transforms.ToTensor(),\n",
    "        tv_transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "\n",
    "    # 加载数据集\n",
    "    trainset = tv_datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
    "    testset = tv_datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "    print('Data has been collected.')\n",
    "\n",
    "    # 创建模型\n",
    "    model = build_model()\n",
    "    print('Model built')\n",
    "\n",
    "    # 训练模型并获取历史记录\n",
    "    history = train(model, train_loader, test_loader,num_epochs)\n",
    "    history['train_loss'] = [float(item) for item in history['train_loss']]\n",
    "    history['test_acc'] = [float(item) for item in history['test_acc']]\n",
    "    \n",
    "    # 绘制损失曲线\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'])\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    # 绘制准确率曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['test_acc'])\n",
    "    plt.title('Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "803bf691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T22:11:50.536772Z",
     "iopub.status.busy": "2025-03-15T22:11:50.536509Z",
     "iopub.status.idle": "2025-03-15T22:11:50.541820Z",
     "shell.execute_reply": "2025-03-15T22:11:50.540998Z"
    },
    "papermill": {
     "duration": 0.078508,
     "end_time": "2025-03-15T22:11:50.543050",
     "exception": false,
     "start_time": "2025-03-15T22:11:50.464542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.12,\n",
       " 10.18,\n",
       " 10.61,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8,\n",
       " 9.8]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b98fb7e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T22:11:50.689638Z",
     "iopub.status.busy": "2025-03-15T22:11:50.689373Z",
     "iopub.status.idle": "2025-03-15T22:11:50.695902Z",
     "shell.execute_reply": "2025-03-15T22:11:50.694930Z"
    },
    "papermill": {
     "duration": 0.08037,
     "end_time": "2025-03-15T22:11:50.697280",
     "exception": false,
     "start_time": "2025-03-15T22:11:50.616910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.9456232576204275,\n",
       " 2.795109136405083,\n",
       " 2.663832001369926,\n",
       " 2.5808569213592203,\n",
       " 2.450904085911643,\n",
       " 2.311991942815126,\n",
       " 2.3026524735373557,\n",
       " 2.3025930833579804,\n",
       " 2.302585126800611,\n",
       " 2.3025840939994264,\n",
       " 2.302584092994604,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485,\n",
       " 2.3025840929945485]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa070564",
   "metadata": {
    "papermill": {
     "duration": 0.070984,
     "end_time": "2025-03-15T22:11:50.840009",
     "exception": false,
     "start_time": "2025-03-15T22:11:50.769025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6870860,
     "sourceId": 11035511,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19078.488263,
   "end_time": "2025-03-15T22:11:53.576253",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-15T16:53:55.087990",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
