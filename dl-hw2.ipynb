{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","cell_execution_strategy":"setup"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11503849,"sourceType":"datasetVersion","datasetId":7212539}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport re\nimport random\nimport json\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"8rmBu5x_F914","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:30:58.647151Z","iopub.execute_input":"2025-04-28T10:30:58.647603Z","iopub.status.idle":"2025-04-28T10:31:01.904749Z","shell.execute_reply.started":"2025-04-28T10:30:58.647579Z","shell.execute_reply":"2025-04-28T10:31:01.904173Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\nSOS_token = tokenizer.bos_token_id  # 使用 GPT2 的 <bos> 作为 SOS\nEOS_token = tokenizer.eos_token_id  # 使用 GPT2 的 <eos> 作为 EOS\nvocab_size = len(tokenizer)\n\n# For English, lowercase, trim, and remove non-letter characters\ndef normalizeEng(s):\n    '''\n    process the English sentence\n    '''\n    s = s.lower().strip() # remove leading and trailing spaces then tokenize\n    s = re.sub(r\"([.!?])\", r\" \\1\", s) # add spaces around .!? to separate them from words\n    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s) # replace other characters with spaces\n    return s.strip()\n# For Chinese, trim, and remove other characters\ndef normalizeChi(s):\n    s = s.strip()\n    s = re.sub(r\"([.!?。])\", r\" \\1 \", s)\n    s = re.sub(r\"[^\\u4e00-\\u9fff\\sa-zA-Z!！?。.]+\", r\" \", s)\n    return s.strip()","metadata":{"id":"TMYe8T7uGRqM","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:01.905830Z","iopub.execute_input":"2025-04-28T10:31:01.906186Z","iopub.status.idle":"2025-04-28T10:31:10.344404Z","shell.execute_reply.started":"2025-04-28T10:31:01.906166Z","shell.execute_reply":"2025-04-28T10:31:10.343837Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fcacab16c444944a1b22b8789cc5cb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3de3c4617b074d859e47509816ffe3e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32523745f21c4897b268b337adc70531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a8553dcdc8c44a4833bac8f99502eea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e72708b2b3c4fb28660227576adc7f5"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def readLangs():\n    '''\n    read txt file, process sentence, convert them into pairs\n    '''\n    print(\"Reading lines...\")\n\n    # Read the file and split into lines\n    lines = open(dir, encoding='utf-8').read().strip().split('\\n')\n\n    # Split every line into chinese english pairs and normalize\n    pairs = [[normalizeChi(l.split('\\t')[1]),normalizeEng(l.split('\\t')[0])] for l in lines]\n\n    return pairs","metadata":{"id":"8aHM4Dd-GRsZ","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.345073Z","iopub.execute_input":"2025-04-28T10:31:10.345369Z","iopub.status.idle":"2025-04-28T10:31:10.349706Z","shell.execute_reply.started":"2025-04-28T10:31:10.345352Z","shell.execute_reply":"2025-04-28T10:31:10.349203Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def indexesFromSentence(sentence):\n    return tokenizer(sentence)[\"input_ids\"]\n\ndef tensorFromSentence(sentence):\n    indexes = indexesFromSentence(sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(pair[0])\n    target_tensor = tensorFromSentence(pair[1])\n    return (input_tensor, target_tensor)\n\nfrom torch.utils.data import random_split\ntorch.manual_seed(42)\ndef get_dataloader(batch_size, MAX_LENGTH=100):\n    pairs = readLangs()\n\n    n = len(pairs)\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for idx, (inp, tgt) in enumerate(pairs):\n        inp_ids = indexesFromSentence(inp)\n        tgt_ids = indexesFromSentence(tgt)\n        inp_ids.append(EOS_token)\n        tgt_ids.append(EOS_token)\n        input_ids[idx, :len(inp_ids)] = inp_ids\n        target_ids[idx, :len(tgt_ids)] = tgt_ids\n\n    data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                               torch.LongTensor(target_ids).to(device))\n\n    train_size = int(0.9 * len(data))\n    test_size = len(data) - train_size\n\n    train_dataset, test_dataset = random_split(data, [train_size, test_size])\n\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    return train_dataloader, test_dataloader","metadata":{"id":"GqCGhMvbGRuI","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.351641Z","iopub.execute_input":"2025-04-28T10:31:10.351837Z","iopub.status.idle":"2025-04-28T10:31:10.370830Z","shell.execute_reply.started":"2025-04-28T10:31:10.351821Z","shell.execute_reply":"2025-04-28T10:31:10.370315Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import time\n\ndef train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n                decoder_optimizer, criterion):\n    total_loss = 0\n    start_time = time.time()\n    s_time = time.time()\n\n    for i, data in enumerate(dataloader):\n        input_tensor, target_tensor = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n\n        loss = criterion(\n            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n            target_tensor.view(-1)\n        )\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        total_loss += loss.item()\n\n        if i % 100 == 0:\n            print(f'Within one epoch: training {i}/{len(dataloader)} | Time: {time.time() - s_time:.2f}s')\n            s_time = time.time()\n\n    end_time = time.time()\n    epoch_time = end_time - start_time\n    print(f'\\nOne Epoch finished | Total time: {epoch_time:.2f}s | Average loss: {total_loss / len(dataloader):.4f}')\n\n    return total_loss / len(dataloader)","metadata":{"id":"47Pg-jV7GRxn","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.371496Z","iopub.execute_input":"2025-04-28T10:31:10.371719Z","iopub.status.idle":"2025-04-28T10:31:10.377923Z","shell.execute_reply.started":"2025-04-28T10:31:10.371698Z","shell.execute_reply":"2025-04-28T10:31:10.377368Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Encoder","metadata":{"id":"haxLziwjQB6h"}},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.gru(embedded)\n        return output, hidden","metadata":{"id":"3Db62jgGGr7N","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.378661Z","iopub.execute_input":"2025-04-28T10:31:10.378906Z","iopub.status.idle":"2025-04-28T10:31:10.392579Z","shell.execute_reply.started":"2025-04-28T10:31:10.378885Z","shell.execute_reply":"2025-04-28T10:31:10.392030Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Decoder with attention","metadata":{"id":"hr0iXpy3QQcQ"}},{"cell_type":"code","source":"class BahdanauAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(BahdanauAttention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n\n        weights = F.softmax(scores, dim=-1)\n        context = torch.bmm(weights, keys)\n\n        return context, weights\n\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n        super(AttnDecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.attention = BahdanauAttention(hidden_size)\n        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        attentions = torch.cat(attentions, dim=1)\n\n        return decoder_outputs, decoder_hidden, attentions\n\n\n    def forward_step(self, input, hidden, encoder_outputs):\n        embedded =  self.dropout(self.embedding(input))\n\n        query = hidden.permute(1, 0, 2)\n        context, attn_weights = self.attention(query, encoder_outputs)\n        input_gru = torch.cat((embedded, context), dim=2)\n\n        output, hidden = self.gru(input_gru, hidden)\n        output = self.out(output)\n\n        return output, hidden, attn_weights","metadata":{"id":"R0TXVum1QYfH","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.393275Z","iopub.execute_input":"2025-04-28T10:31:10.393519Z","iopub.status.idle":"2025-04-28T10:31:10.406725Z","shell.execute_reply.started":"2025-04-28T10:31:10.393499Z","shell.execute_reply":"2025-04-28T10:31:10.406158Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Training","metadata":{"id":"eqGMQGQBQq8Y"}},{"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"id":"L5CRElCYQk8x","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.407452Z","iopub.execute_input":"2025-04-28T10:31:10.407728Z","iopub.status.idle":"2025-04-28T10:31:10.420084Z","shell.execute_reply.started":"2025-04-28T10:31:10.407693Z","shell.execute_reply":"2025-04-28T10:31:10.419494Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(plot_losses, save_plot_path=\"training_loss.png\"):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # 设置y轴的刻度间隔\n    loc = ticker.MultipleLocator(base=0.01)\n    ax.yaxis.set_major_locator(loc)\n    # 设置y轴的刻度格式，保留两位小数\n    formatter = ticker.FormatStrFormatter('%.2f')\n    ax.yaxis.set_major_formatter(formatter)\n    plt.plot(plot_losses.keys(), plot_losses.values())\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training Loss\")\n    plt.savefig(save_plot_path)  # 保存图像\n    plt.show()","metadata":{"id":"XhhyuouoQlFM","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.420732Z","iopub.execute_input":"2025-04-28T10:31:10.420929Z","iopub.status.idle":"2025-04-28T10:31:10.432021Z","shell.execute_reply.started":"2025-04-28T10:31:10.420908Z","shell.execute_reply":"2025-04-28T10:31:10.431379Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from tqdm import tqdm\nimport pandas as pd\nimport pickle\n\ndef train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,save_pkl_path=\"losses.pkl\"):\n    start = time.time()\n    losses = {}\n\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    criterion = nn.NLLLoss()\n\n    for epoch in tqdm(range(1, n_epochs + 1),desc=\"Training Epochs...\"):\n        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        losses[epoch] = loss\n        print('%s (%d %d%%) loss: %.4f' % (timeSince(start, epoch / n_epochs),\n                                        epoch, epoch / n_epochs * 100, loss))\n        print(f'==== Finished training of {epoch}/{n_epochs} epochs，loss is {loss} ====')\n\n    showPlot(losses)\n    with open(save_pkl_path, 'wb') as f:\n        pickle.dump(losses, f)","metadata":{"id":"68H-g_i6QlCD","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.433698Z","iopub.execute_input":"2025-04-28T10:31:10.433865Z","iopub.status.idle":"2025-04-28T10:31:10.822391Z","shell.execute_reply.started":"2025-04-28T10:31:10.433852Z","shell.execute_reply":"2025-04-28T10:31:10.821836Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Evaluation & attention visualization","metadata":{"id":"ZoVcJDayQze0"}},{"cell_type":"code","source":"def tensor2sentence(input_tensor):\n    return tokenizer.decode(input_tensor)\ndef evaluate(encoder, decoder, input_tensor):\n    with torch.no_grad():\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze()[0]\n\n        decoded_sentence = tensor2sentence(decoded_ids)\n    return decoded_sentence, decoder_attn","metadata":{"id":"Ab1mlwC-QlIp","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.823078Z","iopub.execute_input":"2025-04-28T10:31:10.823391Z","iopub.status.idle":"2025-04-28T10:31:10.828033Z","shell.execute_reply.started":"2025-04-28T10:31:10.823375Z","shell.execute_reply":"2025-04-28T10:31:10.827485Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# visualize attention\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nmyfont = fm.FontProperties(fname=\"/kaggle/input/simhei/SIMHEI.TTF\") #Kaggle需要使用上传的黑体\n\ndef showAttention(input_sentence, output_words, attentions):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(attentions.cpu().numpy(), cmap='plasma')\n    fig.colorbar(cax)\n\n    # Set up axes\n    ax.set_xticklabels([''] + list(input_sentence) +\n                       ['<EOS>'], rotation=90,fontproperties=myfont)\n    ax.set_yticklabels([''] + output_words.split(' ')+\n                       ['<EOS>'])\n\n    # Show label at every tick\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    plt.savefig(f'attention_map_{input_sentence}.png')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.828859Z","iopub.execute_input":"2025-04-28T10:31:10.829107Z","iopub.status.idle":"2025-04-28T10:31:10.841070Z","shell.execute_reply.started":"2025-04-28T10:31:10.829084Z","shell.execute_reply":"2025-04-28T10:31:10.840388Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import json\ndef evaluateRandomly(dataloader, encoder, decoder, save_path='evaluation.json'):\n    results = []  # 创建一个空列表来存储结果\n    for data in dataloader:\n        input_tensor, target_tensor = data\n        input_sentence = tensor2sentence(input_tensor[0]).split('<|endoftext|>', 1)[0]\n        target_sentence = tensor2sentence(target_tensor[0]).split('<|endoftext|', 1)[0]\n        output_sentence, decoder_attn = evaluate(encoder, decoder, input_tensor)\n        output_sentence = output_sentence.split('<|endoftext|', 1)[0]\n\n        # 打印结果\n        print('>', input_sentence)\n        print('=', target_sentence)\n        print('<', output_sentence)\n        print('')\n        \n        showAttention(input_sentence, output_sentence, decoder_attn[0, :len(output_sentence.split(' '))+1, :len(list(input_sentence))+1])\n        \n        # 将结果添加到列表中\n        results.append({\n            'input': input_sentence,\n            'target': target_sentence,\n            'output': output_sentence.split('<|endoftext|>', 1)[0]\n        })\n\n    # 将结果列表写入JSON文件\n    with open(save_path, 'w', encoding='utf-8') as f:\n        json.dump(results, f, ensure_ascii=False, indent=4)","metadata":{"id":"JGHvlDl4RNcx","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:31:10.841771Z","iopub.execute_input":"2025-04-28T10:31:10.842048Z","iopub.status.idle":"2025-04-28T10:31:10.854643Z","shell.execute_reply.started":"2025-04-28T10:31:10.842025Z","shell.execute_reply":"2025-04-28T10:31:10.854036Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## main","metadata":{"id":"V44piJWXSfrR"}},{"cell_type":"code","source":"hidden_size = 128\nbatch_size = 32\ndir = '/kaggle/input/cmn-eng/cmn.txt'\nMAX_LENGTH = 100\n\ntrain_dataloader, test_dataloader = get_dataloader(batch_size)\n\nencoder = EncoderRNN(vocab_size, hidden_size).to(device)\ndecoder = AttnDecoderRNN(hidden_size, vocab_size).to(device)\n\ntrain(train_dataloader, encoder, decoder, 80)","metadata":{"id":"uXXyeWZlSgwP","outputId":"8279b7cc-0c66-4c3b-fb3b-354be519581c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 保存模型\nencoder_path = 'encoder_model.pth'\ndecoder_path = 'decoder_model.pth'\n\ntorch.save(encoder.state_dict(), encoder_path)\ntorch.save(decoder.state_dict(), decoder_path)\n\nprint(f\"Encoder model saved to {encoder_path}\")\nprint(f\"Decoder model saved to {decoder_path}\")","metadata":{"id":"weA68_R5NWbO"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# evaluation\nencoder.eval()\ndecoder.eval()\nevaluateRandomly(test_dataloader,encoder, decoder)","metadata":{"id":"021RkR1NjnTR","outputId":"43aa2f7c-47fa-489c-f27b-3b867cd2ddb2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and eval","metadata":{}},{"cell_type":"code","source":"# 创建模型实例\nhidden_size = 128\nbatch_size = 32\ndir = '/kaggle/input/cmn-eng/cmn.txt'\nMAX_LENGTH = 100\n\ntrain_dataloader, test_dataloader = get_dataloader(batch_size)\n\nencoder = EncoderRNN(vocab_size, hidden_size).to(device)\ndecoder = AttnDecoderRNN(hidden_size, vocab_size).to(device)\n\n# 加载模型参数\nencoder_path = '/kaggle/input/rnn-attention-80/encoder_model.pth'\ndecoder_path = '/kaggle/input/rnn-attention-80/decoder_model.pth'\n\n# 加载参数到模型\nencoder.load_state_dict(torch.load(encoder_path))\ndecoder.load_state_dict(torch.load(decoder_path))\n\n# 将模型设置为评估模式\nencoder.eval()\ndecoder.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:35:05.213564Z","iopub.execute_input":"2025-04-28T10:35:05.213857Z","iopub.status.idle":"2025-04-28T10:35:16.635809Z","shell.execute_reply.started":"2025-04-28T10:35:05.213835Z","shell.execute_reply":"2025-04-28T10:35:16.634955Z"}},"outputs":[{"name":"stdout","text":"Reading lines...\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"AttnDecoderRNN(\n  (embedding): Embedding(50257, 128)\n  (attention): BahdanauAttention(\n    (Wa): Linear(in_features=128, out_features=128, bias=True)\n    (Ua): Linear(in_features=128, out_features=128, bias=True)\n    (Va): Linear(in_features=128, out_features=1, bias=True)\n  )\n  (gru): GRU(256, 128, batch_first=True)\n  (out): Linear(in_features=128, out_features=50257, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"evaluateRandomly(test_dataloader,encoder, decoder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:35:18.890251Z","iopub.execute_input":"2025-04-28T10:35:18.890927Z","iopub.status.idle":"2025-04-28T10:35:46.986890Z","shell.execute_reply.started":"2025-04-28T10:35:18.890892Z","shell.execute_reply":"2025-04-28T10:35:46.986088Z"}},"outputs":[{"name":"stdout","text":"> 我是网球俱乐部的会员 。\n= i belong to a tennis club\n< i m a member of the tennis club\n\n> 汤姆向我问起你 。\n= tom asked me about you\n< tom asked me to help you\n\n> 我想哭 。\n= i feel like crying\n< i want to cry\n\n> 我們覺得很驚訝老虎隊竟然輸掉了比賽 。\n= the tigers lost the game which was a surprise to us\n< we had a hearted for the delay and then\n\n> 社会上满是不称职的医生 。\n= the world is full of incompetent doctors\n< the river is not always following the other\n\n> 我想去看電影 。\n= i d like to go to the movies\n< i want to go to the movies\n\n> 我被小孩围着非常不舒服 。\n= i m very uncomfortable around children\n< i was very uncomfortable around the child\n\n> 我想问他的电话号码是多少 。\n= i want to ask what his phone number is\n< i wanted to ask him to call him from to call\n\n> 如果我现在有 万日元 我会买辆车 。\n= if i had one million yen now i would buy a car\n< if i go to the library i d buy a bus i would go\n\n> 我奶奶患有骨質疏鬆症 。\n= my grandmother suffers from osteoporosis\n< my grandmother suffers from osteoporosis\n\n> 說英語不容易 。\n= it is not easy to speak english\n< speaking english isn t easy\n\n> 不要急著結婚 。\n= there s no rush to get married\n< don t rush into marriage\n\n> 我认为你应该在这里开个账户 。\n= i think you should open an account here\n< i think you should open the police here\n\n> 我很想家 。\n= i was so homesick\n< i m thinking of thinking\n\n> 你可以相信她 。\n= you can count on her\n< you can count to see you\n\n> 我剛吃過午飯 。\n= i ve just eaten lunch\n< i ve just had lunch\n\n> 这个价格不合理 。\n= the price isn t reasonable\n< this is not very well\n\n> 我尽可能快地需要那个 。\n= i need that as soon as possible\n< i need that anyone will need there\n\n> 今天有人缺席嗎\n= is anyone absent today ?\n< is there any sky today ?\n\n> 我能用你的电话吗\n= can i use your telephone ?\n< can i use your phone ?\n\n> 我们尽情在湖里游泳 。\n= we enjoyed swimming in the lake\n< we enjoyed swimming in the lake\n\n> 他從路上撿起一樣白色的東西 。\n= he picked up something white on the street\n< he picked up a white dress\n\n> 他以前曾在北海道 。\n= he has been in hokkaido before\n< he used to live in the sand\n\n> 我喜欢跑步 。\n= i like to run\n< i like running\n\n> 英語在日本被學習 。\n= english is studied in japan\n< english is studied in japan\n\n> 他似乎已經說了謊 。\n= he seems to have told a lie\n< he seems to have told a lie\n\n> 多少錢\n= how much was it ?\n< how much does this cost ?\n\n> 你在哪里   我在一个朋友家 。\n= where were you ? i was at a friend s house\n< where did you get a friend letter\n\n> 你是湯姆的一個朋友 不是嗎\n= you re a friend of tom s aren t you ?\n< you re a friend of tom s aren t you ?\n\n> 我在大學主修化學 。\n= i majored in chemistry at the university\n< i majored in chemistry at college\n\n> 她去散步了 。\n= she went for a walk\n< she went out to go to the theater\n\n> 我不想游泳 。\n= i don t want to swim\n< i don t want to swim\n\n> 你是个优秀的记者 。\n= you re an excellent journalist\n< you re an excellent journalist\n\n> 谁想要它\n= who wants it ?\n< who wants it ?\n\n> 他是最高的男生 。\n= he is the tallest boy\n< he is the tallest boy\n\n> Tom是我爺爺 。\n= tom is my grandfather\n< tom is my grandfather\n\n> 伯恩是瑞士首都 。\n= bern is the capital of switzerland\n< bern is the capital of switzerland\n\n> 你唱歌像天使 。\n= you sing like an angel\n< you sing like a child\n\n> 她每天挣 美元 。\n= she earns dollars per day\n< she earns dollars for dollars\n\n> 你跟湯姆工作了多長時間\n= how long have you worked with tom ?\n< how long did you get up with tom work ?\n\n> 汤姆脑子好使 。\n= tom has a good head on his shoulders\n< tom is very kind\n\n> 它是我們的秘密 。\n= it was our secret\n< it s my secret\n\n> 钟还没响 。\n= the bell hasn t rung yet\n< the bell hasn t rung yet\n\n> 我很高兴你回来了 。\n= i m glad you came over\n< i m glad you re here\n\n> 這顆鈕扣脫落了 。\n= the button came off\n< the button is being repainted\n\n> 有钱还不够 。\n= being rich isn t enough\n< wine can t pay\n\n> 他們自 年以來一直在這裡 。\n= they have been here since\n< they must decide come here\n\n> 無論你到哪裡 我都會跟著你 。\n= wherever you go i ll follow\n< hey will you i m coming with you\n\n> 防微杜漸 。\n= a stitch in time saves nine\n< the bread is very expensive\n\n> 歐洲有許多不同的人 。\n= there are many different people in europe\n< there are no hats in the people\n\n> 诶！汤姆在哪里\n= hey where s tom ?\n< hey where is tom ?\n\n> 你最好立马去睡觉 。\n= you d better go to bed at once\n< you d better go to bed at once\n\n> 她笑眯眯的对我招手 。\n= she waved her hand to me smiling brightly\n< she waved her hand i seem to open the window\n\n> 我们知道我们的权利 。\n= we know our rights\n< we know our rights\n\n> Marie和我同班 。\n= mary and i are in the same class\n< sing me and i are in the united states\n\n> 我要你離我遠一點\n= i want you to get off my back\n< i want you to get my side to stay ?\n\n> 汤姆想要一杯水 。\n= tom wants a glass of water\n< tom wanted a glass of water\n\n> 他缺乏經驗 。\n= he is lacking in experience\n< he s always dressed\n\n> 看起来像个苹果 。\n= it looks like an apple\n< please take a deep breath\n\n> 他睡着的时候 打呼声很响 。\n= he was snoring loudly while he slept\n< he was snoring loudly while he slept\n\n> 說謊是錯誤的 。\n= it is wrong to tell a lie\n< it is wrong to tell lies\n\n> 你要幾個蘋果\n= how many apples do you want ?\n< what do you want to do with you ?\n\n> 她消失了 。\n= she disappeared\n< she divorceded\n\n> 湯姆不喜歡這個主意 。\n= tom didn t like the idea\n< tom doesn t like this noise\n\n> 你要做什么\n= what ll you do ?\n< what do you want ?\n\n> 我觉得这没什么好 。\n= i don t have a good feeling about this\n< i don t think that it s good\n\n> 我想没这个必要 。\n= i don t think that it s necessary\n< i think it s necessary\n\n> 我認為湯姆會高興 。\n= i think tom would be pleased\n< i think tom is happy\n\n> 汤姆给我发了一条有趣的短信 。\n= tom sent me an interesting text\n< tom sent me a short letter\n\n> 先熨烫领子的里面 然后是外面 。\n= iron the inside of collars first and then the outside\n< the phone rang from the fence\n\n> 爲什麼鴕鳥不會飛\n= why can t ostriches fly ?\n< why can t ostriches fly ?\n\n> 汤姆捏了玛丽的手 。\n= tom squeezed mary s hand\n< tom squeezed mary s hand\n\n> 汤姆刚吃完饭 。\n= tom just ate\n< tom is doing it\n\n> 瘧疾是由蚊子傳染的 。\n= malaria is carried by mosquitoes\n< malaria is carried by mosquitoes\n\n> 當你值勤時最好不要抽煙 。\n= you d better not smoke while on duty\n< you d better not smoke while you\n\n> 停止射击 。\n= stop shooting\n< stop shooting\n\n> 他不肯聽我的勸告 。\n= he would not listen to my advice\n< he doesn t know me to my advice\n\n> 請您再說一遍好嗎\n= could you please repeat it once again ?\n< would you please speak english ?\n\n> 我爺爺的聽力不太好 。\n= my grandfather can t hear very well\n< my grandfather can t help\n\n> 沒有人喜歡被人嘲笑 。\n= nobody likes being laughed at\n< nobody likes being laughed at\n\n> 我要买什么\n= what should i buy ?\n< what do you want to buy ?\n\n> 这个几块\n= how much will it be ?\n< how much does it cost ?\n\n> 汤姆没做解释 。\n= tom didn t give an explanation\n< tom didn t do that\n\n> 汤姆认为玛丽可能有进食障碍 。\n= tom thinks mary may have an eating disorder\n< tom thinks that mary may have a special phone\n\n> 湯姆下午會回來 。\n= tom will be back in the afternoon\n< tom will be back in the afternoon\n\n> 你必须做晚饭吗\n= do you have to make dinner ?\n< do you have to do this ?\n\n> 誰給湯姆我的電話\n= who gave tom my phone number ?\n< who gave tom to my phone number ?\n\n> 遇到火警時 撥打  。\n= in case of fire call\n< in case of fire dial\n\n> 但願我是一個好歌手 。\n= i wish i were a good singer\n< i wish i had a good singer\n\n> 我再拿块毛巾过来 。\n= i ll bring one more towel\n< i ate the whole bottle of the cookies\n\n> 我们点了中餐 。\n= we ordered chinese food\n< we ordered chinese food\n\n> 我想要的就是这个 。\n= that s just what i wanted\n< i d like to be this song\n\n> 我得留在家裡 。\n= i had to stay at home\n< i have to stay home\n\n> 出租车到了 。\n= the taxi s here\n< the taxi s go\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}